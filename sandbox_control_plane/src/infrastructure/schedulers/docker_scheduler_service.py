"""
Docker è°ƒåº¦æœåŠ¡

å®ç°è°ƒåº¦ç­–ç•¥ï¼Œé€‰æ‹©æœ€ä¼˜èŠ‚ç‚¹å¹¶åˆ›å»ºå®¹å™¨ã€‚
é›†æˆé¢„çƒ­æ± åŠŸèƒ½ï¼ŒåŠ é€Ÿä¼šè¯åˆ›å»ºã€‚
"""
import asyncio
import logging
from typing import List, Optional
from datetime import datetime

from src.domain.services.scheduler import (
    IScheduler,
    RuntimeNode,
    ScheduleRequest,
)
from src.domain.repositories.runtime_node_repository import IRuntimeNodeRepository
from src.domain.repositories.template_repository import ITemplateRepository
from src.domain.value_objects.execution_request import ExecutionRequest
from src.infrastructure.container_scheduler.base import (
    IContainerScheduler,
    ContainerConfig,
)
from src.infrastructure.warm_pool.warm_pool_manager import WarmPoolManager
from src.infrastructure.executors import ExecutorClient

logger = logging.getLogger(__name__)

# é¢„çƒ­æ± é…ç½®ï¼ˆåŸºäºæ¨¡æ¿ï¼‰
# å‚è€ƒï¼šdocs/sandbox-design-v2.1.md ä¸­çš„é…ç½®ç¤ºä¾‹
WARM_POOL_CONFIG = {
    # é«˜é¢‘æ¨¡æ¿ï¼ˆå¦‚ Python æ•°æ®åˆ†æï¼‰
    "python-datascience": {
        "pool_size": 5,           # ç›®æ ‡æ± å¤§å°
        "min_size": 2,            # æœ€å°ä¿ç•™
        "max_idle_time": 300,     # æœ€å¤§ç©ºé—²æ—¶é—´ï¼ˆç§’ï¼‰
    },
    # ä½é¢‘æ¨¡æ¿
    "python-basic": {
        "pool_size": 3,
        "min_size": 1,
        "max_idle_time": 180,
    },
    "nodejs-basic": {
        "pool_size": 3,
        "min_size": 1,
        "max_idle_time": 180,
    },
}


class DockerSchedulerService(IScheduler):
    """
    Docker è°ƒåº¦æœåŠ¡

    å®ç°è°ƒåº¦ç­–ç•¥ï¼š
    1. ä¼˜å…ˆä½¿ç”¨é¢„çƒ­æ± å®ä¾‹ï¼ˆå¿«é€Ÿå¯åŠ¨ï¼‰
    2. å…¶æ¬¡è€ƒè™‘æ¨¡æ¿äº²å’Œæ€§ï¼ˆé•œåƒå·²ç¼“å­˜ï¼‰
    3. æœ€åä½¿ç”¨è´Ÿè½½å‡è¡¡ï¼ˆæ–°å»ºå®¹å™¨ï¼‰

    é¢„çƒ­æ± è‡ªåŠ¨è¡¥å……ï¼š
    - åœ¨é¦–æ¬¡è°ƒåº¦æŸæ¨¡æ¿æ—¶ï¼Œæ£€æŸ¥é¢„çƒ­æ± æ˜¯å¦ä¸ºç©º
    - å¦‚æœä¸ºç©ºï¼Œè‡ªåŠ¨è¡¥å……åˆ°æœ€å°å¤§å°
    - ä½¿ç”¨é¢„çƒ­æ± å®ä¾‹åï¼Œå¼‚æ­¥è¡¥å……ä¸€ä¸ªæ–°å®ä¾‹
    """

    def __init__(
        self,
        runtime_node_repo: IRuntimeNodeRepository,
        container_scheduler: IContainerScheduler,
        template_repo: ITemplateRepository,
        executor_client: Optional[ExecutorClient] = None,
        executor_port: int = 8080,
        warm_pool_manager: Optional[WarmPoolManager] = None,
        control_plane_url: str = "http://host.docker.internal:8000",
    ):
        self._runtime_node_repo = runtime_node_repo
        self._container_scheduler = container_scheduler
        self._template_repo = template_repo
        self._executor_client = executor_client or ExecutorClient()
        self._executor_port = executor_port
        self._control_plane_url = control_plane_url
        self._warm_pool_manager = warm_pool_manager or WarmPoolManager(
            container_scheduler=container_scheduler,
            idle_timeout_seconds=1800,  # 30 åˆ†é’Ÿ
            max_pool_size_per_template=5,  # æ¯ä¸ªæ¨¡æ¿æœ€å¤š 5 ä¸ªé¢„çƒ­å®ä¾‹
        )

        # ç”¨äºè®°å½•åˆ†é…ç»™ä¼šè¯çš„é¢„çƒ­å®ä¾‹
        self._session_warm_entries: dict = {}

        # è®°å½•å“ªäº›æ¨¡æ¿å·²ç»åˆå§‹åŒ–è¿‡é¢„çƒ­æ± 
        self._initialized_pools: set = set()

    async def schedule(self, request: ScheduleRequest) -> RuntimeNode:
        """
        è°ƒåº¦ä¼šè¯åˆ°æœ€ä¼˜èŠ‚ç‚¹

        è°ƒåº¦ç­–ç•¥ï¼š
        1. æ£€æŸ¥é¢„çƒ­æ± ä¸­æ˜¯å¦æœ‰å¯ç”¨å®ä¾‹
        2. æ£€æŸ¥æ˜¯å¦æœ‰å·²ç¼“å­˜è¯¥æ¨¡æ¿çš„èŠ‚ç‚¹
        3. é€‰æ‹©è´Ÿè½½æœ€ä½çš„å¥åº·èŠ‚ç‚¹

        é¢„çƒ­æ± è‡ªåŠ¨è¡¥å……ï¼š
        - å¦‚æœæ˜¯é¦–æ¬¡ä½¿ç”¨è¯¥æ¨¡æ¿ï¼Œè‡ªåŠ¨è¡¥å……é¢„çƒ­æ± åˆ°æœ€å°å¤§å°
        """
        # ğŸ”§ ä¸´æ—¶ç¦ç”¨é¢„çƒ­æ± è‡ªåŠ¨åˆå§‹åŒ–
        # é¦–æ¬¡ä½¿ç”¨æ¨¡æ¿æ—¶ï¼Œè‡ªåŠ¨åˆå§‹åŒ–é¢„çƒ­æ± 
        # if request.template_id not in self._initialized_pools:
        #     await self._ensure_warm_pool_initialized(request.template_id)
        #     self._initialized_pools.add(request.template_id)

        # 1. æ£€æŸ¥é¢„çƒ­æ± 
        warm_entry = await self._warm_pool_manager.acquire(
            request.template_id,
            request.session_id or ""
        )
        if warm_entry:
            # ä»é¢„çƒ­æ± åˆ†é…ï¼Œè·å–èŠ‚ç‚¹ä¿¡æ¯
            node = await self.get_node(warm_entry.node_id)
            if node:
                logger.info(
                    f"Allocated from warm pool: template={request.template_id}, "
                    f"container={warm_entry.container_id[:12]}, node={node.id}"
                )
                # è®°å½•ä¼šè¯ä¸é¢„çƒ­å®ä¾‹çš„å…³è”
                if request.session_id:
                    self._session_warm_entries[request.session_id] = warm_entry
                return node

        # 2. è·å–æ‰€æœ‰å¥åº·èŠ‚ç‚¹
        healthy_nodes = await self.get_healthy_nodes()
        if not healthy_nodes:
            raise RuntimeError("No healthy runtime nodes available")

        # 3. æŒ‰æ¨¡æ¿äº²å’Œæ€§æ’åº
        affinity_nodes = [
            node for node in healthy_nodes
            if node.has_template(request.template_id)
        ]

        if affinity_nodes:
            # é€‰æ‹©äº²å’ŒèŠ‚ç‚¹ä¸­è´Ÿè½½æœ€ä½çš„
            selected = self._select_least_loaded(affinity_nodes)
            logger.info(f"Selected affinity node: {selected.id} (template cached)")
            return selected

        # 4. ä½¿ç”¨è´Ÿè½½å‡è¡¡é€‰æ‹©èŠ‚ç‚¹
        selected = self._select_least_loaded(healthy_nodes)
        logger.info(f"Selected node by load balancing: {selected.id}")
        return selected

    async def get_node(self, node_id: str) -> Optional[RuntimeNode]:
        """è·å–æŒ‡å®šèŠ‚ç‚¹"""
        node_model = await self._runtime_node_repo.find_by_id(node_id)
        if not node_model:
            return None
        return node_model.to_runtime_node()

    async def get_healthy_nodes(self) -> List[RuntimeNode]:
        """è·å–æ‰€æœ‰å¥åº·èŠ‚ç‚¹"""
        nodes = await self._runtime_node_repo.find_by_status("online")
        return [node.to_runtime_node() for node in nodes]

    async def mark_node_unhealthy(self, node_id: str) -> None:
        """æ ‡è®°èŠ‚ç‚¹ä¸ºä¸å¥åº·"""
        await self._runtime_node_repo.update_status(node_id, "offline")
        logger.warning(f"Marked node {node_id} as unhealthy")

    def _select_least_loaded(self, nodes: List[RuntimeNode]) -> RuntimeNode:
        """
        ä»èŠ‚ç‚¹åˆ—è¡¨ä¸­é€‰æ‹©è´Ÿè½½æœ€ä½çš„èŠ‚ç‚¹

        é€‰æ‹©é€»è¾‘ï¼š
        1. è´Ÿè½½æ¯”ç‡æœ€ä½
        2. å¦‚æœæ¯”ç‡ç›¸åŒï¼Œé€‰æ‹©ä¼šè¯æ•°æœ€å°‘çš„
        """
        return min(
            nodes,
            key=lambda n: (n.get_load_ratio(), n.session_count)
        )

    async def create_container_for_session(
        self,
        session_id: str,
        template_id: str,
        image: str,
        resource_limit,
        env_vars: dict,
        workspace_path: str,
    ) -> str:
        """
        ä¸ºä¼šè¯åˆ›å»ºå®¹å™¨

        Returns:
            å®¹å™¨ID
        """
        # æ£€æŸ¥æ˜¯å¦å·²æœ‰é¢„çƒ­å®ä¾‹åˆ†é…ç»™æ­¤ä¼šè¯
        warm_entry = self._session_warm_entries.get(session_id)
        if warm_entry:
            logger.info(
                f"Using warm pool container for session {session_id}: "
                f"{warm_entry.container_id[:12]}"
            )
            # å¼‚æ­¥è¡¥å……é¢„çƒ­æ± ï¼ˆåœ¨åå°ä»»åŠ¡ä¸­æ‰§è¡Œï¼‰
            asyncio.create_task(
                self._replenish_warm_pool_after_use(template_id, image)
            )
            return warm_entry.container_id

        # æ²¡æœ‰é¢„çƒ­å®ä¾‹ï¼Œéœ€è¦åˆ›å»ºæ–°å®¹å™¨
        request = ScheduleRequest(
            template_id=template_id,
            resource_limit=resource_limit,
            session_id=session_id,
        )
        node = await self.schedule(request)

        # åˆ›å»ºå®¹å™¨é…ç½®
        config = ContainerConfig(
            image=image,
            name=f"sandbox-{session_id}",
            env_vars={
                **env_vars,
                "SESSION_ID": session_id,
                "WORKSPACE_PATH": workspace_path,
                "CONTROL_PLANE_URL": self._control_plane_url,
                "DISABLE_BWRAP": "true",  # æœ¬åœ°å¼€å‘ç¦ç”¨ Bubblewrap
            },
            cpu_limit=resource_limit.cpu,
            memory_limit=resource_limit.memory,
            disk_limit=resource_limit.disk,
            workspace_path=workspace_path,
            labels={
                "session_id": session_id,
                "template_id": template_id,
                "managed_by": "sandbox-control-plane",
            },
        )

        # åˆ›å»ºå®¹å™¨
        container_id = await self._container_scheduler.create_container(config)
        await self._container_scheduler.start_container(container_id)

        logger.info(
            f"Created container {container_id} for session {session_id} "
            f"on node {node.id}"
        )

        return container_id

    async def destroy_container(
        self,
        container_id: str,
        timeout: int = 10
    ) -> None:
        """é”€æ¯å®¹å™¨"""
        # æ£€æŸ¥æ˜¯å¦æ˜¯é¢„çƒ­æ± å®ä¾‹
        warm_entry = None
        for entry in self._session_warm_entries.values():
            if entry.container_id == container_id:
                warm_entry = entry
                break

        if warm_entry:
            # é‡Šæ”¾é¢„çƒ­å®ä¾‹ï¼ˆä½¿å…¶å¯ä¾›å…¶ä»–ä¼šè¯ä½¿ç”¨ï¼‰
            await self._warm_pool_manager.release(container_id)
            # æ¸…ç†ä¼šè¯å…³è”
            sessions_to_remove = [
                sid for sid, entry in self._session_warm_entries.items()
                if entry.container_id == container_id
            ]
            for sid in sessions_to_remove:
                del self._session_warm_entries[sid]
            logger.info(f"Released warm pool container {container_id[:12]}")
        else:
            # æ™®é€šå®¹å™¨ï¼Œç›´æ¥é”€æ¯
            try:
                await self._container_scheduler.stop_container(container_id, timeout=timeout)
                await self._container_scheduler.remove_container(container_id)
                logger.info(f"Destroyed container {container_id}")
            except Exception as e:
                logger.error(f"Failed to destroy container {container_id}: {e}")
                raise

    async def get_container_info(self, container_id: str):
        """è·å–å®¹å™¨ä¿¡æ¯"""
        return await self._container_scheduler.get_container_status(container_id)

    async def acquire_warm_instance(self, template_id: str) -> Optional[RuntimeNode]:
        """
        ä»é¢„çƒ­æ± è·å–å®ä¾‹

        å®ç° IScheduler æ¥å£çš„æŠ½è±¡æ–¹æ³•ã€‚

        Returns:
            RuntimeNode å¦‚æœæˆåŠŸåˆ†é…ï¼ŒNone å¦‚æœé¢„çƒ­æ± ä¸ºç©º
        """
        warm_entry = await self._warm_pool_manager.acquire(
            template_id=template_id,
            session_id=""  # æ— ä¼šè¯ IDï¼Œè¡¨ç¤ºç›´æ¥ä»é¢„çƒ­æ± è·å–
        )
        if warm_entry:
            node = await self.get_node(warm_entry.node_id)
            if node:
                logger.info(
                    f"Acquired warm instance from pool: template={template_id}, "
                    f"container={warm_entry.container_id[:12]}, node={node.id}"
                )
                return node
        return None

    async def add_warm_instance(
        self,
        template_id: str,
        node_id: str,
        container_id: str
    ) -> None:
        """
        æ·»åŠ é¢„çƒ­å®ä¾‹

        å®ç° IScheduler æ¥å£çš„æŠ½è±¡æ–¹æ³•ã€‚
        å°†å·²å­˜åœ¨çš„å®¹å™¨æ·»åŠ åˆ°é¢„çƒ­æ± ä¸­ç®¡ç†ã€‚
        """
        from src.infrastructure.warm_pool.warm_pool_entry import WarmPoolEntry

        # åˆ›å»ºé¢„çƒ­æ± æ¡ç›®
        entry = WarmPoolEntry(
            template_id=template_id,
            node_id=node_id,
            container_id=container_id,
            container_name="",  # å·²å­˜åœ¨çš„å®¹å™¨ï¼Œå¯èƒ½æ²¡æœ‰åç§°
            image="",  # å·²å­˜åœ¨çš„å®¹å™¨
            status="available",
            created_at=datetime.now(),
        )

        # å°†é¢„çƒ­å®ä¾‹æ·»åŠ åˆ°ç®¡ç†å™¨
        await self._warm_pool_manager.add(entry)

        logger.info(
            f"Added warm instance to pool: template={template_id}, "
            f"container={container_id[:12]}, node={node_id}"
        )

    async def remove_warm_instance(
        self,
        template_id: str,
        node_id: str
    ) -> None:
        """
        ç§»é™¤é¢„çƒ­å®ä¾‹

        å®ç° IScheduler æ¥å£çš„æŠ½è±¡æ–¹æ³•ã€‚
        ä»é¢„çƒ­æ± ä¸­ç§»é™¤æŒ‡å®šèŠ‚ç‚¹ä¸Šçš„æŒ‡å®šæ¨¡æ¿å®ä¾‹ã€‚
        """
        # è·å–è¯¥æ¨¡æ¿çš„é¢„çƒ­æ± 
        pool = self._warm_pool_manager._warm_pool.get(template_id, [])

        # æ‰¾åˆ°å¹¶ç§»é™¤åŒ¹é…çš„æ¡ç›®
        to_remove = []
        for entry in pool:
            if entry.node_id == node_id and entry.template_id == template_id:
                to_remove.append(entry)

        # ç§»é™¤å¹¶é”€æ¯å®¹å™¨
        for entry in to_remove:
            try:
                # ä»å®¹å™¨ç´¢å¼•ä¸­ç§»é™¤
                if entry.container_id in self._warm_pool_manager._container_index:
                    del self._warm_pool_manager._container_index[entry.container_id]

                # ä»é¢„çƒ­æ± ä¸­ç§»é™¤
                pool.remove(entry)

                # é”€æ¯å®¹å™¨
                await self._warm_pool_manager._container_scheduler.remove_container(entry.container_id)

                logger.info(
                    f"Removed warm instance: template={template_id}, "
                    f"container={entry.container_id[:12]}, node={node_id}"
                )
            except Exception as e:
                logger.warning(f"Failed to remove warm instance {entry.container_id[:12]}: {e}")

    async def _ensure_warm_pool_initialized(self, template_id: str) -> None:
        """
        ç¡®ä¿é¢„çƒ­æ± å·²åˆå§‹åŒ–åˆ°æœ€å°å¤§å°

        åœ¨é¦–æ¬¡ä½¿ç”¨æŸä¸ªæ¨¡æ¿æ—¶è°ƒç”¨ï¼Œè‡ªåŠ¨è¡¥å……é¢„çƒ­æ± ã€‚
        """
        config = WARM_POOL_CONFIG.get(template_id, {})
        min_size = config.get("min_size", 1)

        # è·å–æ¨¡æ¿ä¿¡æ¯
        template = await self._template_repo.find_by_id(template_id)
        if not template:
            logger.warning(f"Template {template_id} not found, skipping warm pool initialization")
            return

        # è·å–é»˜è®¤èŠ‚ç‚¹
        nodes = await self.get_healthy_nodes()
        if not nodes:
            logger.warning("No healthy nodes available for warm pool initialization")
            return

        default_node = nodes[0]

        try:
            # è¡¥å……åˆ°æœ€å°å¤§å°
            await self._warm_pool_manager.replenish(
                template_id=template_id,
                target_size=min_size,
                image=template.image,
                node_id=default_node.id,
                resource_limit=template.default_resources,
                env_vars={},
                workspace_path_template="s3://sandbox-bucket/sessions/{session_id}",
            )
            logger.info(
                f"Initialized warm pool for {template_id}: "
                f"min_size={min_size}, image={template.image}"
            )
        except Exception as e:
            logger.error(f"Failed to initialize warm pool for {template_id}: {e}")

    async def _replenish_warm_pool_after_use(self, template_id: str, image: str) -> None:
        """
        ä½¿ç”¨é¢„çƒ­æ± å®ä¾‹åï¼Œå¼‚æ­¥è¡¥å……ä¸€ä¸ªæ–°å®ä¾‹

        è¿™ç¡®ä¿é¢„çƒ­æ± å§‹ç»ˆä¿æŒå¯ç”¨çŠ¶æ€ã€‚
        """
        try:
            # è·å–é»˜è®¤èŠ‚ç‚¹
            nodes = await self.get_healthy_nodes()
            if not nodes:
                logger.warning("No healthy nodes available for warm pool replenishment")
                return

            default_node = nodes[0]

            # è·å–æ¨¡æ¿é…ç½®
            config = WARM_POOL_CONFIG.get(template_id, {})
            pool_size = config.get("pool_size", 2)

            # è¡¥å……åˆ°ç›®æ ‡å¤§å°
            await self._warm_pool_manager.replenish(
                template_id=template_id,
                target_size=pool_size,
                image=image,
                node_id=default_node.id,
                resource_limit=None,  # ä½¿ç”¨æ¨¡æ¿é»˜è®¤å€¼
                env_vars={},
                workspace_path_template="s3://sandbox-bucket/sessions/{session_id}",
            )
            logger.info(f"Replenished warm pool for {template_id}")
        except Exception as e:
            logger.error(f"Failed to replenish warm pool for {template_id}: {e}")

    async def execute(
        self,
        session_id: str,
        container_id: str,
        execution_request: ExecutionRequest,
    ) -> str:
        """
        æäº¤æ‰§è¡Œè¯·æ±‚åˆ°å®¹å™¨å†…çš„æ‰§è¡Œå™¨

        é€šè¿‡ HTTP ä¸è¿è¡Œåœ¨å®¹å™¨å†…çš„ sandbox-executor é€šä¿¡ã€‚

        Args:
            session_id: ä¼šè¯ ID
            container_id: å®¹å™¨ ID
            execution_request: æ‰§è¡Œè¯·æ±‚

        Returns:
            execution_id: æ‰§è¡Œä»»åŠ¡ ID

        Raises:
            ConnectionError: æ— æ³•è¿æ¥åˆ°æ‰§è¡Œå™¨
            TimeoutError: æ‰§è¡Œå™¨å“åº”è¶…æ—¶
        """
        # è·å–å®¹å™¨ä¿¡æ¯ä»¥æ„å»ºæ‰§è¡Œå™¨ URL
        container_info = await self._container_scheduler.get_container_status(container_id)

        # æ„å»ºæ‰§è¡Œå™¨ URL
        # ä½¿ç”¨å®¹å™¨åç§°åœ¨ Docker å†…éƒ¨ç½‘ç»œä¸­è¿›è¡Œé€šä¿¡
        # å®¹å™¨åç§°æ ¼å¼: sandbox-{session_id}
        container_name = container_info.name
        executor_url = f"http://{container_name}:{self._executor_port}"

        logger.info(f"Submitting execution to executor: {executor_url}, session_id={session_id}, container_id={container_id}")

        # ä½¿ç”¨æ‰§è¡Œå™¨å®¢æˆ·ç«¯æäº¤è¯·æ±‚
        try:
            execution_id = await self._executor_client.submit_execution(
                executor_url=executor_url,
                execution_id=execution_request.execution_id or "",
                session_id=session_id,
                code=execution_request.code,
                language=execution_request.language,
                event=execution_request.event,
                timeout=execution_request.timeout,
                env_vars=execution_request.env_vars,
            )

            logger.info(f"Execution submitted successfully: execution_id={execution_id}, session_id={session_id}")

            return execution_id

        except Exception as e:
            logger.error(f"Failed to submit execution to executor: {executor_url}, error={e}")
            raise
