"""
Kubernetes å®¹å™¨è°ƒåº¦å™¨

ä½¿ç”¨å®˜æ–¹ Python kubernetes å®¢æˆ·ç«¯å®ç° Pod çš„åˆ›å»ºå’Œç®¡ç†ã€‚

æ”¯æŒ S3 workspace æŒ‚è½½ï¼šå½“ workspace_path ä»¥ s3:// å¼€å¤´æ—¶ï¼Œ
Pod ä¼šé€šè¿‡ s3fs sidecar å®¹å™¨å°† S3 bucket æŒ‚è½½åˆ° /workspace ç›®å½•ã€‚

æ”¯æŒ Python ä¾èµ–å®‰è£…ï¼šæŒ‰ç…§ sandbox-design-v2.1.md ç« èŠ‚ 5 è®¾è®¡ã€‚
"""
import asyncio
import json
import os
from typing import Optional, List
from urllib.parse import urlparse

from kubernetes import client, config
from kubernetes.client import (
    V1Pod,
    V1PodSpec,
    V1ObjectMeta,
    V1Container,
    V1ContainerPort,
    V1EnvVar,
    V1ResourceRequirements,
    V1Volume,
    V1VolumeMount,
    V1PersistentVolumeClaimVolumeSource,
    V1PersistentVolumeClaim,
    V1PersistentVolumeClaimSpec,
    V1SecurityContext,
    V1Capabilities,
    V1PodSecurityContext,
    V1EmptyDirVolumeSource,
)
from kubernetes.client.rest import ApiException

from src.infrastructure.container_scheduler.base import (
    IContainerScheduler,
    ContainerConfig,
    ContainerInfo,
    ContainerResult,
)
from src.infrastructure.config.settings import get_settings
from src.infrastructure.logging import get_logger

logger = get_logger(__name__)


class K8sScheduler(IContainerScheduler):
    """
    Kubernetes å®¹å™¨è°ƒåº¦å™¨

    é€šè¿‡ Kubernetes API ç®¡ç† Pod ç”Ÿå‘½å‘¨æœŸã€‚
    """

    def __init__(
        self,
        namespace: str = "sandbox-runtime",
        kube_config_path: Optional[str] = None,
        service_account_token: Optional[str] = None,
    ):
        """
        åˆå§‹åŒ– K8s è°ƒåº¦å™¨

        Args:
            namespace: Kubernetes å‘½åç©ºé—´
            kube_config_path: kubeconfig æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼Œç”¨äºæœ¬åœ°å¼€å‘ï¼‰
            service_account_token: ServiceAccount Tokenï¼ˆç”¨äº Pod å†…è¿è¡Œï¼‰
        """
        self._namespace = namespace

        # åŠ è½½ Kubernetes é…ç½®
        if service_account_token:
            # åœ¨ Pod å†…è¿è¡Œï¼Œä½¿ç”¨ ServiceAccount
            self._load_incluster_config()
        elif kube_config_path:
            # ä½¿ç”¨æŒ‡å®šçš„ kubeconfig æ–‡ä»¶
            config.load_kube_config(config_file=kube_config_path)
        else:
            # å°è¯•åŠ è½½é»˜è®¤ kubeconfig
            try:
                config.load_kube_config()
            except Exception:
                # å¦‚æœ kubeconfig ä¸å­˜åœ¨ï¼Œå°è¯•ä½¿ç”¨ in-cluster é…ç½®
                try:
                    self._load_incluster_config()
                except Exception:
                    # æœ€åå°è¯•ä½¿ç”¨é»˜è®¤é…ç½®ï¼ˆç”¨äºæœ¬åœ°å¼€å‘ï¼‰
                    from kubernetes.client import Configuration
                    Configuration.set_default(Configuration())

        # åˆ›å»º API å®¢æˆ·ç«¯
        self._core_v1 = client.CoreV1Api()
        self._initialized = False

    def _load_incluster_config(self):
        """åŠ è½½ in-cluster é…ç½®"""
        config.load_incluster_config()
        logger.info("Loaded in-cluster Kubernetes config")

    async def _ensure_connected(self) -> bool:
        """ç¡®ä¿ K8s è¿æ¥å·²å»ºç«‹"""
        if not self._initialized:
            try:
                # æµ‹è¯•è¿æ¥ - ä½¿ç”¨å½“å‰ namespace çš„ Pod åˆ—è¡¨ä»£æ›¿ namespace åˆ—è¡¨
                # è¿™æ ·åªéœ€è¦ namespace çº§åˆ«çš„æƒé™ï¼Œä¸éœ€è¦ cluster çº§åˆ«çš„æƒé™
                self._core_v1.list_namespaced_pod(self._namespace, limit=1)
                self._initialized = True
                logger.info(f"Connected to Kubernetes cluster, namespace: {self._namespace}")
            except Exception as e:
                logger.error(f"Failed to connect to Kubernetes: {e}")
                raise
        return self._initialized

    async def close(self) -> None:
        """å…³é—­è¿æ¥ï¼ˆKubernetes å®¢æˆ·ç«¯æ˜¯æ— çŠ¶æ€çš„ï¼Œæ— éœ€æ˜¾å¼å…³é—­ï¼‰"""
        self._initialized = False

    def _parse_s3_workspace(self, workspace_path: str) -> Optional[dict]:
        """
        è§£æ S3 workspace è·¯å¾„

        Args:
            workspace_path: S3 è·¯å¾„ï¼Œæ ¼å¼: s3://bucket/sessions/{session_id}/

        Returns:
            åŒ…å« bucket, prefix çš„å­—å…¸ï¼Œå¦‚æœä¸æ˜¯ S3 è·¯å¾„åˆ™è¿”å› None
        """
        if not workspace_path or not workspace_path.startswith("s3://"):
            return None

        parsed = urlparse(workspace_path)
        return {
            "bucket": parsed.netloc,
            "prefix": parsed.path.lstrip('/'),
        }

    def _build_pod_name(self, session_id: str) -> str:
        """ç”Ÿæˆ Pod åç§°"""
        # K8s Pod åç§°éœ€è¦ç¬¦åˆ DNS å­åŸŸåè§„åˆ™
        # åªèƒ½åŒ…å«å°å†™å­—æ¯ã€æ•°å­—å’Œ '-'ï¼Œä¸”å¼€å¤´å’Œç»“å°¾å¿…é¡»æ˜¯å­—æ¯æ•°å­—
        pod_name = f"sandbox-{session_id.lower()}"
        # æ›¿æ¢ä¸ç¬¦åˆè§„åˆ™çš„å­—ç¬¦
        pod_name = ''.join(c if c.isalnum() or c == '-' else '-' for c in pod_name)
        # ç¡®ä¿ä¸ä»¥ '-' å¼€å¤´æˆ–ç»“å°¾
        pod_name = pod_name.strip('-')
        # é™åˆ¶é•¿åº¦ï¼ˆK8s Pod åç§°æœ€å¤š 253 å­—ç¬¦ï¼‰
        return pod_name[:253]

    def _build_s3_sidecar_container(
        self,
        s3_bucket: str,
        s3_prefix: str,
        s3_endpoint_url: str,
        s3_access_key: str,
        s3_secret_key: str,
        dependencies: Optional[List[str]] = None,
    ) -> V1Container:
        """
        æ„å»ºç”¨äºæŒ‚è½½ S3 çš„ sidecar å®¹å™¨

        Args:
            s3_bucket: S3 bucket åç§°
            s3_prefix: S3 è·¯å¾„å‰ç¼€
            s3_endpoint_url: S3 ç«¯ç‚¹ URL
            s3_access_key: S3 è®¿é—®å¯†é’¥ ID
            s3_secret_key: S3 è®¿é—®å¯†é’¥
            dependencies: pip åŒ…è§„èŒƒåˆ—è¡¨

        Returns:
            V1Container å¯¹è±¡
        """
        # ä¾èµ–å®‰è£…è„šæœ¬
        dependency_install_script = ""
        if dependencies:
            pip_specs = []
            for dep in dependencies:
                if isinstance(dep, dict):
                    name = dep.get("name", "")
                    version = dep.get("version", "")
                    if version:
                        pip_specs.append(f"{name}{version}")
                    else:
                        pip_specs.append(name)
                elif isinstance(dep, str):
                    pip_specs.append(dep)

            deps_list = " ".join(f'"{spec}"' for spec in pip_specs)
            dependency_install_script = f"""
# å®‰è£… Python ä¾èµ–
echo "ğŸ“¦ Installing dependencies: {len(dependencies)} packages"
mkdir -p /workspace/.venv/

if pip3 install \\
    --target /workspace/.venv/ \\
    --isolated \\
    --no-warn-script-location \\
    --disable-pip-version-check \\
    --index-url https://pypi.org/simple/ \\
    {deps_list}; then
    echo "âœ… Dependencies installed successfully"
else
    echo "âŒ Failed to install dependencies"
    exit 1
fi

chown -R 1000:1000 /workspace/.venv/
"""

        # s3fs æŒ‚è½½è„šæœ¬
        path_style_option = "-o use_path_request_style" if s3_endpoint_url else ""

        mount_script = f"""
#!/bin/sh
set -e

# åˆ›å»º s3fs å‡­è¯æ–‡ä»¶
echo "{s3_access_key}:{s3_secret_key}" > /tmp/.passwd-s3fs
chmod 600 /tmp/.passwd-s3fs

# æŒ‚è½½ S3 bucket
echo "Mounting S3 bucket {s3_bucket}..."
mkdir -p /workspace
s3fs {s3_bucket} /workspace \\
    -o passwd_file=/tmp/.passwd-s3fs \\
    -o url={s3_endpoint_url or "https://s3.amazonaws.com"} \\
    {path_style_option} \\
    -o allow_other \\
    -o umask=000

# ç­‰å¾…æŒ‚è½½å®Œæˆ
sleep 2

# ç¡®ä¿ä¼šè¯ç›®å½•å­˜åœ¨
SESSION_PATH="/workspace/{s3_prefix}"
mkdir -p "$SESSION_PATH"

echo "âœ… S3 mounted successfully at $SESSION_PATH"

# å®‰è£…ä¾èµ–ï¼ˆå¦‚æœæœ‰ï¼‰
{dependency_install_script}

# ä¿æŒå®¹å™¨è¿è¡Œä»¥ç»´æŒæŒ‚è½½
echo "Sidecar container keeping S3 mount alive..."
tail -f /dev/null
"""

        return V1Container(
            name="s3-mount",
            image="xueshanf/s3fs:latest",
            image_pull_policy="IfNotPresent",  # ä¼˜å…ˆä½¿ç”¨æœ¬åœ°é•œåƒ
            security_context=V1SecurityContext(
                privileged=True,  # s3fs FUSE æŒ‚è½½éœ€è¦ç‰¹æƒ
                capabilities=V1Capabilities(add=["SYS_ADMIN"]),
            ),
            env=[
                V1EnvVar(name="S3_BUCKET", value=s3_bucket),
                V1EnvVar(name="S3_PREFIX", value=s3_prefix),
                V1EnvVar(name="S3_ENDPOINT_URL", value=s3_endpoint_url or "https://s3.amazonaws.com"),
            ],
            command=["sh", "-c", mount_script],
            volume_mounts=[
                V1VolumeMount(
                    name="workspace",
                    mount_path="/workspace",
                )
            ],
        )

    def _build_executor_container(
        self,
        config: ContainerConfig,
        use_s3_mount: bool,
        has_dependencies: bool,
    ) -> V1Container:
        """
        æ„å»ºä¸» executor å®¹å™¨

        Args:
            config: å®¹å™¨é…ç½®
            use_s3_mount: æ˜¯å¦ä½¿ç”¨ S3 æŒ‚è½½
            has_dependencies: æ˜¯å¦æœ‰ä¾èµ–åŒ…

        Returns:
            V1Container å¯¹è±¡
        """
        env_vars = [
            V1EnvVar(name=k, value=v)
            for k, v in config.env_vars.items()
        ]

        # æ·»åŠ  S3 ç›¸å…³ç¯å¢ƒå˜é‡
        if use_s3_mount:
            s3_workspace = self._parse_s3_workspace(config.workspace_path)
            settings = get_settings()
            env_vars.extend([
                V1EnvVar(name="WORKSPACE_PATH", value="/workspace"),
                V1EnvVar(name="S3_BUCKET", value=s3_workspace["bucket"]),
                V1EnvVar(name="S3_PREFIX", value=s3_workspace["prefix"]),
            ])

        # æ·»åŠ  PYTHONPATH ç¯å¢ƒå˜é‡ä»¥æ”¯æŒä¾èµ–å¯¼å…¥
        if has_dependencies:
            if use_s3_mount:
                env_vars.append(V1EnvVar(
                    name="PYTHONPATH",
                    value="/app:/workspace/.venv:/workspace"
                ))
                env_vars.append(V1EnvVar(
                    name="SANDBOX_VENV_PATH",
                    value="/workspace/.venv/"
                ))
            else:
                env_vars.append(V1EnvVar(
                    name="PYTHONPATH",
                    value="/workspace/.venv/:/workspace:$PYTHONPATH"
                ))
                env_vars.append(V1EnvVar(
                    name="SANDBOX_VENV_PATH",
                    value="/workspace/.venv/"
                ))

        # èµ„æºé™åˆ¶
        resources = V1ResourceRequirements(
            limits={
                "cpu": config.cpu_limit,
                "memory": config.memory_limit,
                "ephemeral-storage": config.disk_limit,
            },
            requests={
                "cpu": config.cpu_limit,
                "memory": config.memory_limit,
            },
        )

        # å®¹å™¨ç«¯å£
        ports = [
            V1ContainerPort(
                container_port=8080,
                name="executor",
                protocol="TCP",
            )
        ]

        # å·æŒ‚è½½
        volume_mounts = [
            V1VolumeMount(
                name="workspace",
                mount_path="/workspace",
            )
        ]

        # å®‰å…¨ä¸Šä¸‹æ–‡
        security_context = V1SecurityContext(
            run_as_non_root=True,
            run_as_user=1000,
            run_as_group=1000,
            allow_privilege_escalation=False,
            capabilities=V1Capabilities(drop=["ALL"]),
            read_only_root_filesystem=False,
        )

        # å¦‚æœæœ‰ä¾èµ–å®‰è£…ï¼Œä½¿ç”¨å¯åŠ¨è„šæœ¬
        command = None
        if has_dependencies and not use_s3_mount:
            dependencies_json = config.labels.get("dependencies", "")
            dependencies = json.loads(dependencies_json) if dependencies_json else []

            pip_specs = []
            for dep in dependencies:
                if isinstance(dep, dict):
                    name = dep.get("name", "")
                    version = dep.get("version", "")
                    if version:
                        pip_specs.append(f"{name}{version}")
                    else:
                        pip_specs.append(name)
                elif isinstance(dep, str):
                    pip_specs.append(dep)

            deps_list = " ".join(f'"{spec}"' for spec in pip_specs)
            install_script = f"""
#!/bin/sh
set -e
echo "ğŸ“¦ Installing dependencies..."
mkdir -p /workspace/.venv/
pip3 install \\
    --target /workspace/.venv/ \\
    --isolated \\
    --no-warn-script-location \\
    --disable-pip-version-check \\
    --index-url https://pypi.org/simple/ \\
    {deps_list}
echo "âœ… Dependencies installed"
# å¯åŠ¨ executor
exec python -m executor.interfaces.http.rest
"""
            command = ["sh", "-c", install_script]

        return V1Container(
            name="executor",
            image=config.image,
            image_pull_policy="IfNotPresent",  # ä¼˜å…ˆä½¿ç”¨æœ¬åœ°é•œåƒ
            command=command,
            env=env_vars,
            resources=resources,
            ports=ports,
            volume_mounts=volume_mounts,
            security_context=security_context,
        )

    async def create_pvc_for_workspace(
        self,
        session_id: str,
        workspace_path: str,
    ) -> Optional[str]:
        """
        ä¸º S3 workspace åˆ›å»º PVC

        Args:
            session_id: ä¼šè¯ ID
            workspace_path: S3 workspace è·¯å¾„

        Returns:
            PVC åç§°ï¼Œå¦‚æœä¸éœ€è¦ PVC åˆ™è¿”å› None
        """
        s3_workspace = self._parse_s3_workspace(workspace_path)
        if not s3_workspace:
            return None

        # åœ¨å®é™…ç”Ÿäº§ç¯å¢ƒä¸­ï¼Œè¿™é‡Œä¼šåˆ›å»ºä¸€ä¸ªæŒ‡å‘ S3 CSI Driver çš„ PVC
        # å¯¹äºç®€åŒ–å®ç°ï¼Œæˆ‘ä»¬ä½¿ç”¨ emptyDir + s3fs sidecar
        # å¦‚æœéœ€è¦çœŸå®çš„ S3 CSIï¼Œéœ€è¦é¢„å…ˆåˆ›å»º StorageClass å’Œ PVC æ¨¡æ¿
        return None

    async def create_container(self, config: ContainerConfig) -> str:
        """
        åˆ›å»º Kubernetes Pod

        Pod é…ç½®ï¼š
        - ä¸»å®¹å™¨: executorï¼ˆè¿è¡Œç”¨æˆ·ä»£ç ï¼‰
        - Sidecar å®¹å™¨: s3-mountï¼ˆæŒ‚è½½ S3 bucketï¼Œå¯é€‰ï¼‰

        S3 Workspace æŒ‚è½½ï¼š
        å½“ workspace_path ä»¥ s3:// å¼€å¤´æ—¶ï¼Œä¼šåˆ›å»º s3fs sidecar å®¹å™¨å°† S3 bucket æŒ‚è½½åˆ° /workspaceï¼š
        - ä½¿ç”¨ emptyDir å…±äº«å·
        - s3-mount å®¹å™¨ä»¥ç‰¹æƒæ¨¡å¼è¿è¡Œï¼ŒæŒ‚è½½ S3 åˆ°å…±äº«å·
        - executor å®¹å™¨ä»å…±äº«å·è¯»å–æ–‡ä»¶

        Python ä¾èµ–å®‰è£…ï¼š
        - å¦‚æœæœ‰ä¾èµ–ï¼Œs3fs sidecar ä¼šå…ˆå®‰è£…ä¾èµ–å†æŒ‚è½½
        - é S3 æ¨¡å¼ä¸‹ï¼Œexecutor å®¹å™¨ä¼šåœ¨å¯åŠ¨æ—¶å®‰è£…ä¾èµ–
        """
        await self._ensure_connected()

        pod_name = self._build_pod_name(config.name)
        s3_workspace = self._parse_s3_workspace(config.workspace_path)
        use_s3_mount = s3_workspace is not None

        # æ£€æŸ¥æ˜¯å¦æœ‰ä¾èµ–
        dependencies_json = config.labels.get("dependencies", "")
        has_dependencies = bool(dependencies_json)

        # æ„å»ºå®¹å™¨åˆ—è¡¨
        containers = []

        # ä¸» executor å®¹å™¨
        executor_container = self._build_executor_container(
            config=config,
            use_s3_mount=use_s3_mount,
            has_dependencies=has_dependencies,
        )
        containers.append(executor_container)

        # S3 sidecar å®¹å™¨ï¼ˆå¦‚æœéœ€è¦ï¼‰
        if use_s3_mount:
            settings = get_settings()
            dependencies = json.loads(dependencies_json) if dependencies_json else None

            s3_sidecar = self._build_s3_sidecar_container(
                s3_bucket=s3_workspace["bucket"],
                s3_prefix=s3_workspace["prefix"],
                s3_endpoint_url=settings.s3_endpoint_url or "",
                s3_access_key=settings.s3_access_key_id,
                s3_secret_key=settings.s3_secret_access_key,
                dependencies=dependencies,
            )
            containers.append(s3_sidecar)

        # æ„å»ºå·
        volumes = []
        if use_s3_mount:
            # ä½¿ç”¨ emptyDir åœ¨ä¸¤ä¸ªå®¹å™¨é—´å…±äº« S3 æŒ‚è½½ç‚¹
            volumes.append(
                V1Volume(
                    name="workspace",
                    empty_dir=V1EmptyDirVolumeSource(
                        medium="Memory",  # ä½¿ç”¨å†…å­˜ä½œä¸ºå­˜å‚¨ä»‹è´¨
                    ),
                )
            )
        else:
            # é S3 æ¨¡å¼ï¼Œä½¿ç”¨ emptyDir ä½œä¸ºä¸´æ—¶å­˜å‚¨
            volumes.append(
                V1Volume(
                    name="workspace",
                    empty_dir=V1EmptyDirVolumeSource(),
                )
            )

        # æ„å»ºæ ‡ç­¾
        labels = {
            "app": "sandbox-executor",  # åŒ¹é… sandbox-executor service selector
            "sandbox-session": config.name,
            "sandbox-type": "execution",
        }
        labels.update(config.labels)

        # æ„å»º Pod Spec
        pod = V1Pod(
            metadata=V1ObjectMeta(
                name=pod_name,
                labels=labels,
                annotations={
                    "sandbox-session-id": config.name,
                },
            ),
            spec=V1PodSpec(
                containers=containers,
                volumes=volumes,
                restart_policy="Never",
                host_network=False,
                termination_grace_period_seconds=30,
                # ä½¿ç”¨é»˜è®¤ DNS ç­–ç•¥ (ClusterFirst)ï¼Œå…è®¸ Pod ä½¿ç”¨ K8s é›†ç¾¤ DNS
                # è¿™å¯¹äº executor ä¸ control plane é€šä¿¡å¾ˆé‡è¦
            ),
        )

        try:
            # åˆ›å»º Pod
            created_pod = await asyncio.to_thread(
                self._core_v1.create_namespaced_pod,
                namespace=self._namespace,
                body=pod,
            )
            logger.info(
                f"Created pod {created_pod.metadata.name} for session {config.name} "
                f"in namespace {self._namespace} (S3 mount: {use_s3_mount})"
            )
            return created_pod.metadata.name

        except ApiException as e:
            logger.error(f"Failed to create pod: {e}")
            raise

    async def start_container(self, container_id: str) -> None:
        """
        å¯åŠ¨ Pod

        æ³¨æ„ï¼šKubernetes Pod åˆ›å»ºåä¼šè‡ªåŠ¨å¯åŠ¨ï¼Œæ­¤æ–¹æ³•ä¸ºå…¼å®¹æ¥å£ä¿ç•™
        """
        await self._ensure_connected()
        # K8s Pod åˆ›å»ºåè‡ªåŠ¨å¯åŠ¨ï¼Œæ— éœ€æ˜¾å¼è°ƒç”¨
        logger.debug(f"Pod {container_id} starts automatically after creation")

    async def stop_container(
        self,
        container_id: str,
        timeout: int = 30
    ) -> None:
        """
        åœæ­¢ï¼ˆåˆ é™¤ï¼‰Pod

        Args:
            container_id: Pod åç§°
            timeout: ä¼˜é›…ç»ˆæ­¢è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
        """
        await self._ensure_connected()
        try:
            await asyncio.to_thread(
                self._core_v1.delete_namespaced_pod,
                name=container_id,
                namespace=self._namespace,
                grace_period_seconds=timeout,
            )
            logger.info(f"Stopped pod {container_id}")
        except ApiException as e:
            if e.status == 404:
                logger.warning(f"Pod {container_id} not found")
            else:
                logger.error(f"Failed to stop pod {container_id}: {e}")
                raise

    async def remove_container(
        self,
        container_id: str,
        force: bool = False
    ) -> None:
        """
        åˆ é™¤ Pod

        Args:
            container_id: Pod åç§°
            force: æ˜¯å¦å¼ºåˆ¶åˆ é™¤ï¼ˆgrace_period_seconds=0ï¼‰
        """
        await self._ensure_connected()
        try:
            await asyncio.to_thread(
                self._core_v1.delete_namespaced_pod,
                name=container_id,
                namespace=self._namespace,
                grace_period_seconds=0 if force else 30,
            )
            logger.info(f"Removed pod {container_id}")
        except ApiException as e:
            if e.status == 404:
                logger.warning(f"Pod {container_id} not found")
            else:
                logger.warning(f"Failed to remove pod {container_id}: {e}")

    async def get_container_status(self, container_id: str) -> ContainerInfo:
        """
        è·å– Pod çŠ¶æ€

        Args:
            container_id: Pod åç§°

        Returns:
            ContainerInfo å¯¹è±¡
        """
        await self._ensure_connected()
        try:
            pod = await asyncio.to_thread(
                self._core_v1.read_namespaced_pod,
                name=container_id,
                namespace=self._namespace,
            )

            # è½¬æ¢ K8s Pod çŠ¶æ€åˆ° ContainerInfo
            phase = pod.status.phase
            if phase == "Running":
                # æ£€æŸ¥å®¹å™¨çŠ¶æ€
                if pod.status.container_statuses:
                    for container_status in pod.status.container_statuses:
                        if container_status.name == "executor":
                            if container_status.state.terminated:
                                phase = "exited"
                            elif container_status.state.waiting:
                                phase = "waiting"
                            break

            # è·å– IP åœ°å€
            ip_address = pod.status.pod_ip

            # è·å–æ—¶é—´ä¿¡æ¯
            created_at = pod.metadata.creation_timestamp.isoformat() if pod.metadata.creation_timestamp else ""
            started_at = pod.status.start_time.isoformat() if pod.status.start_time else None

            # è·å–é€€å‡ºç ï¼ˆå¦‚æœå·²ç»ˆæ­¢ï¼‰
            exit_code = None
            if pod.status.container_statuses:
                for container_status in pod.status.container_statuses:
                    if container_status.name == "executor" and container_status.state.terminated:
                        exit_code = container_status.state.terminated.exit_code
                        break

            # è·å–é•œåƒåç§°
            image = ""
            if pod.spec.containers:
                for container in pod.spec.containers:
                    if container.name == "executor":
                        image = container.image
                        break

            return ContainerInfo(
                id=container_id,
                name=container_id,
                image=image,
                status=phase.lower(),
                ip_address=ip_address,
                created_at=created_at,
                started_at=started_at,
                exited_at=None,
                exit_code=exit_code,
            )

        except ApiException as e:
            if e.status == 404:
                logger.error(f"Pod {container_id} not found")
                raise ValueError(f"Pod {container_id} not found") from e
            else:
                logger.error(f"Failed to get pod status {container_id}: {e}")
                raise

    async def is_container_running(self, container_id: str) -> bool:
        """
        æ£€æŸ¥ Pod æ˜¯å¦æ­£åœ¨è¿è¡Œ

        Args:
            container_id: Pod åç§°

        Returns:
            bool: Pod æ˜¯å¦è¿è¡Œä¸­
        """
        try:
            container_info = await self.get_container_status(container_id)
            return container_info.status == "running"
        except Exception as e:
            logger.warning(f"Failed to check pod {container_id} status: {e}")
            return False

    async def get_container_logs(
        self,
        container_id: str,
        tail: int = 100,
        since: Optional[str] = None
    ) -> str:
        """
        è·å– Pod æ—¥å¿—

        Args:
            container_id: Pod åç§°
            tail: è¿”å›æœ€åå‡ è¡Œ
            since: æ—¶é—´æˆ³ï¼ˆå¯é€‰ï¼‰

        Returns:
            æ—¥å¿—å­—ç¬¦ä¸²
        """
        await self._ensure_connected()
        try:
            logs = await asyncio.to_thread(
                self._core_v1.read_namespaced_pod_log,
                name=container_id,
                namespace=self._namespace,
                container="executor",
                tail_lines=tail,
                since_seconds=None,  # since_time éœ€è¦è½¬æ¢
            )
            return logs
        except ApiException as e:
            logger.error(f"Failed to get logs for pod {container_id}: {e}")
            raise

    async def wait_container(
        self,
        container_id: str,
        timeout: Optional[int] = None
    ) -> ContainerResult:
        """
        ç­‰å¾… Pod æ‰§è¡Œå®Œæˆ

        Args:
            container_id: Pod åç§°
            timeout: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰

        Returns:
            ContainerResult å¯¹è±¡
        """
        await self._ensure_connected()

        async def _wait() -> ContainerResult:
            while True:
                try:
                    pod = await asyncio.to_thread(
                        self._core_v1.read_namespaced_pod,
                        name=container_id,
                        namespace=self._namespace,
                    )

                    # æ£€æŸ¥ Pod çŠ¶æ€
                    if pod.status.phase == "Succeeded":
                        # è·å–æ—¥å¿—
                        logs = await self.get_container_logs(container_id, tail=-1)
                        return ContainerResult(
                            status="completed",
                            stdout=logs,
                            stderr="",
                            exit_code=0,
                        )
                    elif pod.status.phase == "Failed":
                        # è·å–æ—¥å¿—
                        logs = await self.get_container_logs(container_id, tail=-1)
                        return ContainerResult(
                            status="failed",
                            stdout=logs,
                            stderr="Pod failed",
                            exit_code=1,
                        )

                    # æ£€æŸ¥å®¹å™¨çŠ¶æ€
                    if pod.status.container_statuses:
                        for container_status in pod.status.container_statuses:
                            if container_status.name == "executor":
                                if container_status.state.terminated:
                                    logs = await self.get_container_logs(container_id, tail=-1)
                                    terminated = container_status.state.terminated
                                    return ContainerResult(
                                        status="completed" if terminated.exit_code == 0 else "failed",
                                        stdout=logs,
                                        stderr="",
                                        exit_code=terminated.exit_code,
                                    )

                    # ç­‰å¾…åé‡è¯•
                    await asyncio.sleep(1)

                except ApiException as e:
                    if e.status == 404:
                        return ContainerResult(
                            status="failed",
                            stdout="",
                            stderr=f"Pod {container_id} not found",
                            exit_code=1,
                        )
                    raise

        try:
            if timeout:
                return await asyncio.wait_for(_wait(), timeout=timeout)
            else:
                return await _wait()

        except asyncio.TimeoutError:
            logger.warning(f"Pod {container_id} timed out")
            return ContainerResult(
                status="timeout",
                stdout="",
                stderr=f"Pod execution timed out after {timeout}s",
                exit_code=124,
            )

    async def ping(self) -> bool:
        """
        æ£€æŸ¥ Kubernetes è¿æ¥çŠ¶æ€

        Returns:
            bool: è¿æ¥æ˜¯å¦æ­£å¸¸
        """
        try:
            await self._ensure_connected()
            # æµ‹è¯•è¿æ¥
            await asyncio.to_thread(
                self._core_v1.list_namespace,
                limit=1,
            )
            return True
        except Exception as e:
            logger.error(f"Kubernetes ping failed: {e}")
            return False

    def _parse_memory_to_bytes(self, value: str) -> int:
        """
        è§£æå†…å­˜é™åˆ¶ä¸ºå­—èŠ‚æ•°

        Args:
            value: å¦‚ "512Mi", "1Gi"

        Returns:
            å­—èŠ‚æ•°
        """
        value = value.strip()
        if value.endswith("Gi") or value.endswith("GB") or value.endswith("G"):
            return int(float(value[:-2]) * 1024 * 1024 * 1024)
        elif value.endswith("Mi") or value.endswith("MB") or value.endswith("M"):
            return int(float(value[:-2]) * 1024 * 1024)
        elif value.endswith("Ki") or value.endswith("KB") or value.endswith("K"):
            return int(float(value[:-2]) * 1024)
        else:
            # é»˜è®¤ä¸º MB
            return int(float(value) * 1024 * 1024)

    def _parse_disk_to_bytes(self, value: str) -> int:
        """è§£æç£ç›˜é™åˆ¶ä¸ºå­—èŠ‚æ•°"""
        return self._parse_memory_to_bytes(value)
