"""
Kubernetes å®¹å™¨è°ƒåº¦å™¨

ä½¿ç”¨å®˜æ–¹ Python kubernetes å®¢æˆ·ç«¯å®ç° Pod çš„åˆ›å»ºå’Œç®¡ç†ã€‚

MinIO + s3fs æ¶æ„ï¼š
- Control Plane é€šè¿‡ S3 API å°†æ–‡ä»¶å†™å…¥ MinIO çš„ /sessions/{session_id}/ è·¯å¾„
- Executor Pod åœ¨å¯åŠ¨è„šæœ¬ä¸­æŒ‚è½½ s3fsï¼Œå°† S3 bucket çš„ session å­ç›®å½•æŒ‚è½½åˆ° /workspace
- s3fs è¿›ç¨‹å’Œ executor è¿›ç¨‹è¿è¡Œåœ¨åŒä¸€å®¹å™¨å†…

Python ä¾èµ–å®‰è£…ï¼šæŒ‰ç…§ sandbox-design-v2.1.md ç« èŠ‚ 5 è®¾è®¡ã€‚
"""
import asyncio
import json
import os
from typing import Optional, List
from urllib.parse import urlparse

from kubernetes import client, config
from kubernetes.client import (
    V1Pod,
    V1PodSpec,
    V1ObjectMeta,
    V1Container,
    V1ContainerPort,
    V1EnvVar,
    V1ResourceRequirements,
    V1Volume,
    V1VolumeMount,
    V1HostPathVolumeSource,
    V1PersistentVolumeClaim,
    V1PersistentVolumeClaimSpec,
    V1PersistentVolumeClaimVolumeSource,
    V1ObjectMeta as V1ObjectMeta_imported,
    V1SecurityContext,
    V1Capabilities,
    V1PodSecurityContext,
    V1EmptyDirVolumeSource,
    V1SecretVolumeSource,
)
from kubernetes.client.rest import ApiException

from src.infrastructure.container_scheduler.base import (
    IContainerScheduler,
    ContainerConfig,
    ContainerInfo,
    ContainerResult,
)
from src.infrastructure.config.settings import get_settings
from src.infrastructure.logging import get_logger

logger = get_logger(__name__)


def s3_prefix_from_path(prefix: str) -> str:
    """
    ä» S3 è·¯å¾„å‰ç¼€ä¸­æå–ä¼šè¯ ID

    Args:
        prefix: S3 è·¯å¾„å‰ç¼€ï¼Œå¦‚ "sessions/test-001/workspace"

    Returns:
        ä¼šè¯ IDï¼Œå¦‚ "test-001"
    """
    parts = prefix.strip('/').split('/')
    if len(parts) >= 2 and parts[0] == "sessions":
        return parts[1]
    return prefix


class K8sScheduler(IContainerScheduler):
    """
    Kubernetes å®¹å™¨è°ƒåº¦å™¨

    é€šè¿‡ Kubernetes API ç®¡ç† Pod ç”Ÿå‘½å‘¨æœŸã€‚
    """

    def __init__(
        self,
        namespace: str = "sandbox-system",
        kube_config_path: Optional[str] = None,
        service_account_token: Optional[str] = None,
    ):
        """
        åˆå§‹åŒ– K8s è°ƒåº¦å™¨

        Args:
            namespace: Kubernetes å‘½åç©ºé—´
            kube_config_path: kubeconfig æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼Œç”¨äºæœ¬åœ°å¼€å‘ï¼‰
            service_account_token: ServiceAccount Tokenï¼ˆç”¨äº Pod å†…è¿è¡Œï¼‰
        """
        self._namespace = namespace

        # åŠ è½½ Kubernetes é…ç½®
        if service_account_token:
            # åœ¨ Pod å†…è¿è¡Œï¼Œä½¿ç”¨ ServiceAccount
            self._load_incluster_config()
        elif kube_config_path:
            # ä½¿ç”¨æŒ‡å®šçš„ kubeconfig æ–‡ä»¶
            config.load_kube_config(config_file=kube_config_path)
        else:
            # å°è¯•åŠ è½½é»˜è®¤ kubeconfig
            try:
                config.load_kube_config()
            except Exception:
                # å¦‚æœ kubeconfig ä¸å­˜åœ¨ï¼Œå°è¯•ä½¿ç”¨ in-cluster é…ç½®
                try:
                    self._load_incluster_config()
                except Exception:
                    # æœ€åå°è¯•ä½¿ç”¨é»˜è®¤é…ç½®ï¼ˆç”¨äºæœ¬åœ°å¼€å‘ï¼‰
                    from kubernetes.client import Configuration
                    Configuration.set_default(Configuration())

        # åˆ›å»º API å®¢æˆ·ç«¯
        self._core_v1 = client.CoreV1Api()
        self._initialized = False

    def _load_incluster_config(self):
        """åŠ è½½ in-cluster é…ç½®"""
        config.load_incluster_config()
        logger.info("Loaded in-cluster Kubernetes config")

    async def _ensure_connected(self) -> bool:
        """ç¡®ä¿ K8s è¿æ¥å·²å»ºç«‹"""
        if not self._initialized:
            try:
                # æµ‹è¯•è¿æ¥ - ä½¿ç”¨å½“å‰ namespace çš„ Pod åˆ—è¡¨ä»£æ›¿ namespace åˆ—è¡¨
                # è¿™æ ·åªéœ€è¦ namespace çº§åˆ«çš„æƒé™ï¼Œä¸éœ€è¦ cluster çº§åˆ«çš„æƒé™
                self._core_v1.list_namespaced_pod(self._namespace, limit=1)
                self._initialized = True
                logger.info(f"Connected to Kubernetes cluster, namespace: {self._namespace}")
            except Exception as e:
                logger.error(f"Failed to connect to Kubernetes: {e}")
                raise
        return self._initialized

    async def close(self) -> None:
        """å…³é—­è¿æ¥ï¼ˆKubernetes å®¢æˆ·ç«¯æ˜¯æ— çŠ¶æ€çš„ï¼Œæ— éœ€æ˜¾å¼å…³é—­ï¼‰"""
        self._initialized = False

    def _parse_s3_workspace(self, workspace_path: str) -> Optional[dict]:
        """
        è§£æ S3 workspace è·¯å¾„

        Args:
            workspace_path: S3 è·¯å¾„ï¼Œæ ¼å¼: s3://bucket/sessions/{session_id}/

        Returns:
            åŒ…å« bucket, prefix çš„å­—å…¸ï¼Œå¦‚æœä¸æ˜¯ S3 è·¯å¾„åˆ™è¿”å› None
        """
        if not workspace_path or not workspace_path.startswith("s3://"):
            return None

        parsed = urlparse(workspace_path)
        return {
            "bucket": parsed.netloc,
            "prefix": parsed.path.lstrip('/'),
        }

    def _build_pod_name(self, session_id: str) -> str:
        """ç”Ÿæˆ Pod åç§°"""
        # K8s Pod åç§°éœ€è¦ç¬¦åˆ DNS å­åŸŸåè§„åˆ™
        # åªèƒ½åŒ…å«å°å†™å­—æ¯ã€æ•°å­—å’Œ '-'ï¼Œä¸”å¼€å¤´å’Œç»“å°¾å¿…é¡»æ˜¯å­—æ¯æ•°å­—
        pod_name = f"sandbox-{session_id.lower()}"
        # æ›¿æ¢ä¸ç¬¦åˆè§„åˆ™çš„å­—ç¬¦
        pod_name = ''.join(c if c.isalnum() or c == '-' else '-' for c in pod_name)
        # ç¡®ä¿ä¸ä»¥ '-' å¼€å¤´æˆ–ç»“å°¾
        pod_name = pod_name.strip('-')
        # é™åˆ¶é•¿åº¦ï¼ˆK8s Pod åç§°æœ€å¤š 253 å­—ç¬¦ï¼‰
        return pod_name[:253]


    def _build_executor_container(
        self,
        config: ContainerConfig,
        use_s3_mount: bool,
        has_dependencies: bool,
        session_id: str = None,
        s3_workspace: dict = None,
    ) -> V1Container:
        """
        æ„å»ºä¸» executor å®¹å™¨

        å¦‚æœä½¿ç”¨ S3 æŒ‚è½½ï¼Œå¯åŠ¨è„šæœ¬ä¼šå…ˆæŒ‚è½½ s3fsï¼Œç„¶åå¯åŠ¨ executor

        Args:
            config: å®¹å™¨é…ç½®
            use_s3_mount: æ˜¯å¦ä½¿ç”¨ S3 æŒ‚è½½ï¼ˆé€šè¿‡ s3fs åœ¨å®¹å™¨å†…æŒ‚è½½ï¼‰
            has_dependencies: æ˜¯å¦æœ‰ä¾èµ–åŒ…
            session_id: ä¼šè¯ IDï¼ˆç”¨äº S3 å­ç›®å½•æŒ‚è½½ï¼‰
            s3_workspace: S3 workspace é…ç½®ï¼ˆåŒ…å« bucket, prefixï¼‰

        Returns:
            V1Container å¯¹è±¡
        """
        env_vars = [
            V1EnvVar(name=k, value=v)
            for k, v in config.env_vars.items()
        ]

        # æ·»åŠ  S3 ç›¸å…³ç¯å¢ƒå˜é‡
        s3_workspace = self._parse_s3_workspace(config.workspace_path)
        if s3_workspace:
            env_vars.extend([
                V1EnvVar(name="WORKSPACE_PATH", value="/workspace"),
                V1EnvVar(name="S3_BUCKET", value=s3_workspace["bucket"]),
                V1EnvVar(name="S3_PREFIX", value=s3_workspace["prefix"]),
            ])

        # æ·»åŠ  PYTHONPATH ç¯å¢ƒå˜é‡ä»¥æ”¯æŒä¾èµ–å¯¼å…¥
        if has_dependencies:
            # ä¾èµ–å®‰è£…åˆ°æœ¬åœ° /opt/sandbox-venv
            env_vars.append(V1EnvVar(
                name="PYTHONPATH",
                value="/opt/sandbox-venv:/app:/workspace"
            ))
            env_vars.append(V1EnvVar(
                name="SANDBOX_VENV_PATH",
                value="/opt/sandbox-venv"
            ))

        # èµ„æºé™åˆ¶
        resources = V1ResourceRequirements(
            limits={
                "cpu": config.cpu_limit,
                "memory": config.memory_limit,
                "ephemeral-storage": config.disk_limit,
            },
            requests={
                "cpu": config.cpu_limit,
                "memory": config.memory_limit,
            },
        )

        # å®¹å™¨ç«¯å£
        ports = [
            V1ContainerPort(
                container_port=8080,
                name="executor",
                protocol="TCP",
            )
        ]

        # å·æŒ‚è½½
        volume_mounts = [
            V1VolumeMount(
                name="workspace",
                mount_path="/workspace",
            )
        ]
        if use_s3_mount:
            volume_mounts.append(
                V1VolumeMount(
                    name="s3fs-passwd",
                    mount_path="/etc/s3fs-passwd",
                    read_only=True,
                )
            )

        # å®‰å…¨ä¸Šä¸‹æ–‡ - s3fs éœ€è¦ privileged å’Œ root ç”¨æˆ·
        # æ³¨æ„ï¼šprivileged=True æ—¶å®¹å™¨å¿…é¡»ä»¥ root è¿è¡Œï¼Œä»¥ä¾¿è¿›è¡Œ FUSE æŒ‚è½½
        # éœ€è¦æ˜¾å¼è®¾ç½® runAsUser=0 æ¥è¦†ç›– Dockerfile ä¸­çš„ USER æŒ‡ä»¤
        # æœ‰ä¾èµ–æ—¶ä¹Ÿéœ€è¦ root æ¥å®‰è£…ä¾èµ–ï¼Œç„¶åç”¨ gosu åˆ‡æ¢åˆ° sandbox ç”¨æˆ·
        needs_root = use_s3_mount or has_dependencies
        security_context = V1SecurityContext(
            # s3fs æŒ‚è½½æˆ–ä¾èµ–å®‰è£…éœ€è¦ rootï¼Œæœ€ç»ˆä½¿ç”¨ gosu åˆ‡æ¢åˆ° sandbox ç”¨æˆ·
            run_as_non_root=not needs_root,
            run_as_user=0 if needs_root else 1000,  # 0 = rootï¼Œæ˜¾å¼è®¾ç½®ä»¥è¦†ç›– Dockerfile USER
            run_as_group=0 if needs_root else 1000,
            allow_privilege_escalation=use_s3_mount,  # s3fs éœ€è¦ç‰¹æƒ
            capabilities=V1Capabilities(drop=["ALL"]) if not needs_root else None,
            read_only_root_filesystem=False,
            privileged=use_s3_mount,  # s3fs éœ€è¦ privileged æ¨¡å¼
        )

        # æ„å»ºå¯åŠ¨å‘½ä»¤
        command = None
        if use_s3_mount:
            # è·å–è®¾ç½®
            settings = get_settings()
            minio_url = settings.s3_endpoint_url or "http://minio.sandbox-system.svc.cluster.local:9000"
            bucket = s3_workspace["bucket"]

            # S3 æŒ‚è½½è„šæœ¬ï¼ˆä½¿ç”¨ bucket æŒ‚è½½ + bind mount æ–¹æ¡ˆï¼‰
            s3_prefix = s3_workspace["prefix"].rstrip('/')
            mount_script = f"""#!/bin/sh
set -e

echo "ğŸ“‚ Mounting S3 bucket {bucket} to /mnt/s3-root (session: {session_id})..."

# æŒ‚è½½æ•´ä¸ª S3 bucket åˆ°ä¸´æ—¶ä½ç½®ï¼ˆuid=1000,gid=1000 è®©æŒ‚è½½ç‚¹å¯¹ sandbox ç”¨æˆ·å¯è®¿é—®ï¼‰
mkdir -p /mnt/s3-root
s3fs {bucket} /mnt/s3-root \\
    -o url={minio_url} \\
    -o use_path_request_style \\
    -o allow_other \\
    -o uid=1000 \\
    -o gid=1000 \\
    -o passwd_file=/etc/s3fs-passwd/s3fs-passwd &

S3FS_PID=$!
echo "s3fs started with PID: $S3FS_PID"

# ç­‰å¾…æŒ‚è½½å®Œæˆ
sleep 2

# åˆ›å»º session workspace ç›®å½•ï¼ˆä½¿ç”¨å®Œæ•´ S3 å‰ç¼€ï¼‰
SESSION_PATH="/mnt/s3-root/{s3_prefix}"
echo "Ensuring session workspace exists: $SESSION_PATH"
mkdir -p "$SESSION_PATH"

# ä½¿ç”¨ bind mount å°† S3 è·¯å¾„æŒ‚è½½åˆ° /workspaceï¼ˆ/workspace æ˜¯ emptyDir æŒ‚è½½ç‚¹ï¼‰
mount --bind "$SESSION_PATH" /workspace

# éªŒè¯ bind mount
echo "Workspace bind mounted: $(ls -la /workspace)"

echo "âœ… S3 bucket mounted and workspace linked successfully"
ls -la /workspace/

"""

            # å¦‚æœæœ‰ä¾èµ–ï¼Œå®‰è£…ä¾èµ–
            if has_dependencies:
                dependencies_json = config.labels.get("dependencies", "")
                dependencies = json.loads(dependencies_json) if dependencies_json else []
                pip_specs = []
                for dep in dependencies:
                    if isinstance(dep, dict):
                        name = dep.get("name", "")
                        version = dep.get("version", "")
                        if version:
                            pip_specs.append(f"{name}{version}")
                        else:
                            pip_specs.append(name)
                    elif isinstance(dep, str):
                        pip_specs.append(dep)

                deps_list = " ".join(f'"{spec}"' for spec in pip_specs)
                mount_script += f"""
echo "ğŸ“¦ Installing dependencies..."
VENV_DIR="/opt/sandbox-venv"
mkdir -p $VENV_DIR

pip3 install \\
    --target $VENV_DIR \\
    --no-cache-dir \\
    --no-warn-script-location \\
    --disable-pip-version-check \\
    --index-url https://pypi.org/simple/ \\
    {deps_list}

echo "âœ… Dependencies installed"

export PYTHONPATH="$VENV_DIR:/app:/workspace"
export SANDBOX_VENV_PATH="$VENV_DIR"
"""

            # å¯åŠ¨ executor (å‰å°) - ä½¿ç”¨ gosu åˆ‡æ¢åˆ° sandbox ç”¨æˆ·
            mount_script += """
echo "ğŸš€ Starting executor as sandbox user..."
# ä½¿ç”¨ gosu åˆ‡æ¢åˆ° sandbox ç”¨æˆ·å¹¶å¯åŠ¨ executor
# gosu ä¼šæ­£ç¡®ä¼ é€’ä¿¡å·ï¼Œé¿å…è¿›ç¨‹å˜æˆåƒµå°¸
exec gosu sandbox python -m executor.interfaces.http.rest
"""
            command = ["sh", "-c", mount_script]

        elif has_dependencies:
            # ä¾èµ–ç”± executor å®¹å™¨åœ¨å¯åŠ¨æ—¶å®‰è£…
            dependencies_json = config.labels.get("dependencies", "")
            dependencies = json.loads(dependencies_json) if dependencies_json else []

            pip_specs = []
            for dep in dependencies:
                if isinstance(dep, dict):
                    name = dep.get("name", "")
                    version = dep.get("version", "")
                    if version:
                        pip_specs.append(f"{name}{version}")
                    else:
                        pip_specs.append(name)
                elif isinstance(dep, str):
                    pip_specs.append(dep)

            deps_list = " ".join(f'"{spec}"' for spec in pip_specs)
            install_script = f"""
#!/bin/sh
set -e
echo "ğŸ“¦ Installing dependencies..."

# å°†ä¾èµ–å®‰è£…åˆ°å®¹å™¨æœ¬åœ°æ–‡ä»¶ç³»ç»Ÿ
VENV_DIR="/opt/sandbox-venv"
mkdir -p $VENV_DIR
mkdir -p /tmp/pip-cache

echo "Installing dependencies to: $VENV_DIR"

pip3 install \\
    --target $VENV_DIR \\
    --cache-dir /tmp/pip-cache \\
    --no-cache-dir \\
    --no-warn-script-location \\
    --disable-pip-version-check \\
    --index-url https://pypi.org/simple/ \\
    {deps_list}

echo "âœ… Dependencies installed"
rm -rf /tmp/pip-cache

# ä¿®å¤ venv ç›®å½•æƒé™ï¼ˆä»¥ root å®‰è£…ï¼Œéœ€è¦è®© sandbox ç”¨æˆ·å¯è¯»ï¼‰
chown -R sandbox:sandbox /opt/sandbox-venv

# å¯åŠ¨ executor - ä½¿ç”¨ gosu åˆ‡æ¢åˆ° sandbox ç”¨æˆ·
echo "ğŸš€ Starting executor as sandbox user..."
exec gosu sandbox python -m executor.interfaces.http.rest
"""
            command = ["sh", "-c", install_script]

        return V1Container(
            name="executor",
            image=config.image,
            image_pull_policy="IfNotPresent",  # ä¼˜å…ˆä½¿ç”¨æœ¬åœ°é•œåƒ
            command=command,
            env=env_vars,
            resources=resources,
            ports=ports,
            volume_mounts=volume_mounts,
            security_context=security_context,
        )

    async def create_container(self, config: ContainerConfig) -> str:
        """
        åˆ›å»º Kubernetes Pod - ä½¿ç”¨ s3fs åœ¨ executor å®¹å™¨å†…æŒ‚è½½

        æ¶æ„è¯´æ˜ï¼š
        - Control Plane é€šè¿‡ S3 API å°†æ–‡ä»¶å†™å…¥ MinIO çš„ /sessions/{session_id}/ è·¯å¾„
        - Executor Pod åœ¨å¯åŠ¨è„šæœ¬ä¸­æŒ‚è½½ s3fsï¼Œå°† S3 bucket çš„ session å­ç›®å½•æŒ‚è½½åˆ° /workspace
        - s3fs è¿›ç¨‹å’Œ executor è¿›ç¨‹è¿è¡Œåœ¨åŒä¸€å®¹å™¨å†…
        - å¦‚æœæœ‰ä¾èµ–ï¼Œexecutor å®¹å™¨ä¼šåœ¨å¯åŠ¨æ—¶å®‰è£…ä¾èµ–
        """
        await self._ensure_connected()

        pod_name = self._build_pod_name(config.name)
        s3_workspace = self._parse_s3_workspace(config.workspace_path)
        use_s3_mount = s3_workspace is not None

        # æ£€æŸ¥æ˜¯å¦æœ‰ä¾èµ–
        dependencies_json = config.labels.get("dependencies", "")
        has_dependencies = bool(dependencies_json)

        # æå– session_id ä»…ç”¨äºæ—¥å¿—è®°å½•ï¼ˆæŒ‚è½½ä½¿ç”¨å®Œæ•´ s3_prefixï¼‰
        session_id = s3_prefix_from_path(s3_workspace["prefix"]) if s3_workspace else config.name

        # æ„å»ºå®¹å™¨åˆ—è¡¨ - åªæœ‰ executor å®¹å™¨
        containers = []

        # æ„å»º executor å®¹å™¨ï¼ˆåœ¨å¯åŠ¨è„šæœ¬ä¸­æŒ‚è½½ s3fsï¼‰
        # æ³¨æ„ï¼šæŒ‚è½½è„šæœ¬ä½¿ç”¨å®Œæ•´çš„ s3_prefixï¼Œè€Œä¸æ˜¯ session_idï¼Œä»¥é¿å…è·¯å¾„å±‚çº§é—®é¢˜
        executor_container = self._build_executor_container(
            config=config,
            use_s3_mount=use_s3_mount,
            has_dependencies=has_dependencies,
            session_id=session_id,
            s3_workspace=s3_workspace,
        )
        containers.append(executor_container)

        # æ„å»ºå·
        volumes = []
        if use_s3_mount:
            # ä½¿ç”¨ emptyDir ç”¨äº s3fs æŒ‚è½½
            volumes.append(
                V1Volume(
                    name="workspace",
                    empty_dir=V1EmptyDirVolumeSource(),
                )
            )
            # æ·»åŠ  s3fs-passwd secret
            volumes.append(
                V1Volume(
                    name="s3fs-passwd",
                    secret=V1SecretVolumeSource(
                        secret_name="s3fs-passwd",
                        default_mode=0o400,
                    ),
                )
            )
        else:
            # æœ¬åœ° workspaceï¼šä½¿ç”¨ emptyDir
            volumes.append(
                V1Volume(
                    name="workspace",
                    empty_dir=V1EmptyDirVolumeSource(),
                )
            )

        # æ„å»ºæ ‡ç­¾ï¼ˆæ’é™¤ dependenciesï¼Œå› ä¸º K8s labels æœ‰ä¸¥æ ¼æ ¼å¼é™åˆ¶ï¼‰
        # dependencies ä¸èƒ½ä½œä¸º labelï¼Œå› ä¸ºåŒ…å«æ–¹æ‹¬å·ã€å¼•å·ç­‰éæ³•å­—ç¬¦
        dependencies_value = config.labels.pop("dependencies", None)
        labels = {
            "app": "sandbox-executor",  # åŒ¹é… sandbox-executor service selector
            "sandbox-session": config.name,
            "sandbox-type": "execution",
        }
        if use_s3_mount:
            labels["mount-method"] = "s3fs"
        labels.update(config.labels)

        # æ„å»º annotationsï¼ˆdependencies æ”¾åœ¨è¿™é‡Œï¼Œæ²¡æœ‰æ ¼å¼é™åˆ¶ï¼‰
        annotations = {
            "sandbox-session-id": config.name,
        }
        if dependencies_value:
            annotations["dependencies"] = dependencies_value
        # æ¢å¤ dependencies åˆ° config.labelsï¼Œé¿å…å½±å“åç»­è°ƒç”¨
        if dependencies_value is not None:
            config.labels["dependencies"] = dependencies_value

        # æ„å»º Pod Spec
        pod = V1Pod(
            metadata=V1ObjectMeta(
                name=pod_name,
                labels=labels,
                annotations=annotations,
            ),
            spec=V1PodSpec(
                containers=containers,
                volumes=volumes,
                restart_policy="Never",
                host_network=False,
                termination_grace_period_seconds=30,
                # ä½¿ç”¨é»˜è®¤ DNS ç­–ç•¥ (ClusterFirst)ï¼Œå…è®¸ Pod ä½¿ç”¨ K8s é›†ç¾¤ DNS
                # è¿™å¯¹äº executor ä¸ control plane é€šä¿¡å¾ˆé‡è¦
            ),
        )

        try:
            # åˆ›å»º Pod
            created_pod = await asyncio.to_thread(
                self._core_v1.create_namespaced_pod,
                namespace=self._namespace,
                body=pod,
            )
            mount_method = "s3fs" if use_s3_mount else "emptyDir"
            logger.info(
                f"Created pod {created_pod.metadata.name} for session {config.name} "
                f"in namespace {self._namespace} (mount method: {mount_method})"
            )
            return created_pod.metadata.name

        except ApiException as e:
            logger.error(f"Failed to create pod: {e}")
            raise

    async def start_container(self, container_id: str) -> None:
        """
        å¯åŠ¨ Pod

        æ³¨æ„ï¼šKubernetes Pod åˆ›å»ºåä¼šè‡ªåŠ¨å¯åŠ¨ï¼Œæ­¤æ–¹æ³•ä¸ºå…¼å®¹æ¥å£ä¿ç•™
        """
        await self._ensure_connected()
        # K8s Pod åˆ›å»ºåè‡ªåŠ¨å¯åŠ¨ï¼Œæ— éœ€æ˜¾å¼è°ƒç”¨
        logger.debug(f"Pod {container_id} starts automatically after creation")

    async def stop_container(
        self,
        container_id: str,
        timeout: int = 30
    ) -> None:
        """
        åœæ­¢ï¼ˆåˆ é™¤ï¼‰Pod

        ä½¿ç”¨ s3fs æ–¹å¼æ—¶ï¼Œæ— éœ€æ¸…ç† PVCï¼Œs3fs æŒ‚è½½åœ¨ Pod åˆ é™¤æ—¶è‡ªåŠ¨æ¸…ç†ã€‚

        Args:
            container_id: Pod åç§°
            timeout: ä¼˜é›…ç»ˆæ­¢è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
        """
        await self._ensure_connected()

        try:
            await asyncio.to_thread(
                self._core_v1.delete_namespaced_pod,
                name=container_id,
                namespace=self._namespace,
                grace_period_seconds=timeout,
            )
            logger.info(f"Stopped pod {container_id}")
        except ApiException as e:
            if e.status == 404:
                logger.warning(f"Pod {container_id} not found")
            else:
                logger.error(f"Failed to stop pod {container_id}: {e}")
                raise

    async def remove_container(
        self,
        container_id: str,
        force: bool = False
    ) -> None:
        """
        åˆ é™¤ Pod

        ä½¿ç”¨ s3fs æ–¹å¼æ—¶ï¼Œæ— éœ€æ¸…ç† PVCï¼Œs3fs æŒ‚è½½åœ¨ Pod åˆ é™¤æ—¶è‡ªåŠ¨æ¸…ç†ã€‚

        Args:
            container_id: Pod åç§°
            force: æ˜¯å¦å¼ºåˆ¶åˆ é™¤ï¼ˆgrace_period_seconds=0ï¼‰
        """
        await self._ensure_connected()

        try:
            await asyncio.to_thread(
                self._core_v1.delete_namespaced_pod,
                name=container_id,
                namespace=self._namespace,
                grace_period_seconds=0 if force else 30,
            )
            logger.info(f"Removed pod {container_id}")
        except ApiException as e:
            if e.status == 404:
                logger.warning(f"Pod {container_id} not found")
            else:
                logger.warning(f"Failed to remove pod {container_id}: {e}")

    async def get_container_status(self, container_id: str) -> ContainerInfo:
        """
        è·å– Pod çŠ¶æ€

        Args:
            container_id: Pod åç§°

        Returns:
            ContainerInfo å¯¹è±¡
        """
        await self._ensure_connected()
        try:
            pod = await asyncio.to_thread(
                self._core_v1.read_namespaced_pod,
                name=container_id,
                namespace=self._namespace,
            )

            # è½¬æ¢ K8s Pod çŠ¶æ€åˆ° ContainerInfo
            phase = pod.status.phase
            if phase == "Running" and pod.status.container_statuses:
                for container_status in pod.status.container_statuses:
                    if container_status.name == "executor":
                        if container_status.state.terminated:
                            phase = "exited"
                        elif container_status.state.waiting:
                            phase = "waiting"
                        break

            ip_address = pod.status.pod_ip
            created_at = pod.metadata.creation_timestamp.isoformat() if pod.metadata.creation_timestamp else ""
            started_at = pod.status.start_time.isoformat() if pod.status.start_time else None

            # è·å–é€€å‡ºç ï¼ˆå¦‚æœå·²ç»ˆæ­¢ï¼‰
            exit_code = None
            if pod.status.container_statuses:
                for container_status in pod.status.container_statuses:
                    if container_status.name == "executor" and container_status.state.terminated:
                        exit_code = container_status.state.terminated.exit_code
                        break

            # è·å–é•œåƒåç§°
            image = ""
            if pod.spec.containers:
                for container in pod.spec.containers:
                    if container.name == "executor":
                        image = container.image
                        break

            return ContainerInfo(
                id=container_id,
                name=container_id,
                image=image,
                status=phase.lower(),
                ip_address=ip_address,
                created_at=created_at,
                started_at=started_at,
                exited_at=None,
                exit_code=exit_code,
            )

        except ApiException as e:
            if e.status == 404:
                logger.error(f"Pod {container_id} not found")
                raise ValueError(f"Pod {container_id} not found") from e
            else:
                logger.error(f"Failed to get pod status {container_id}: {e}")
                raise

    async def is_container_running(self, container_id: str) -> bool:
        """
        æ£€æŸ¥ Pod æ˜¯å¦æ­£åœ¨è¿è¡Œ

        Args:
            container_id: Pod åç§°

        Returns:
            bool: Pod æ˜¯å¦è¿è¡Œä¸­
        """
        try:
            container_info = await self.get_container_status(container_id)
            return container_info.status == "running"
        except Exception as e:
            logger.warning(f"Failed to check pod {container_id} status: {e}")
            return False

    async def get_container_logs(
        self,
        container_id: str,
        tail: int = 100,
        since: Optional[str] = None
    ) -> str:
        """
        è·å– Pod æ—¥å¿—

        Args:
            container_id: Pod åç§°
            tail: è¿”å›æœ€åå‡ è¡Œ
            since: æ—¶é—´æˆ³ï¼ˆå¯é€‰ï¼‰

        Returns:
            æ—¥å¿—å­—ç¬¦ä¸²
        """
        await self._ensure_connected()
        try:
            logs = await asyncio.to_thread(
                self._core_v1.read_namespaced_pod_log,
                name=container_id,
                namespace=self._namespace,
                container="executor",
                tail_lines=tail,
                since_seconds=None,  # since_time éœ€è¦è½¬æ¢
            )
            return logs
        except ApiException as e:
            logger.error(f"Failed to get logs for pod {container_id}: {e}")
            raise

    async def wait_container(
        self,
        container_id: str,
        timeout: Optional[int] = None
    ) -> ContainerResult:
        """
        ç­‰å¾… Pod æ‰§è¡Œå®Œæˆ

        Args:
            container_id: Pod åç§°
            timeout: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰

        Returns:
            ContainerResult å¯¹è±¡
        """
        await self._ensure_connected()

        async def _wait() -> ContainerResult:
            while True:
                try:
                    pod = await asyncio.to_thread(
                        self._core_v1.read_namespaced_pod,
                        name=container_id,
                        namespace=self._namespace,
                    )

                    # æ£€æŸ¥ Pod çŠ¶æ€
                    if pod.status.phase == "Succeeded":
                        # è·å–æ—¥å¿—
                        logs = await self.get_container_logs(container_id, tail=-1)
                        return ContainerResult(
                            status="completed",
                            stdout=logs,
                            stderr="",
                            exit_code=0,
                        )
                    elif pod.status.phase == "Failed":
                        # è·å–æ—¥å¿—
                        logs = await self.get_container_logs(container_id, tail=-1)
                        return ContainerResult(
                            status="failed",
                            stdout=logs,
                            stderr="Pod failed",
                            exit_code=1,
                        )

                    # æ£€æŸ¥å®¹å™¨çŠ¶æ€
                    if pod.status.container_statuses:
                        for container_status in pod.status.container_statuses:
                            if container_status.name == "executor" and container_status.state.terminated:
                                logs = await self.get_container_logs(container_id, tail=-1)
                                terminated = container_status.state.terminated
                                return ContainerResult(
                                    status="completed" if terminated.exit_code == 0 else "failed",
                                    stdout=logs,
                                    stderr="",
                                    exit_code=terminated.exit_code,
                                )

                    await asyncio.sleep(1)

                except ApiException as e:
                    if e.status == 404:
                        return ContainerResult(
                            status="failed",
                            stdout="",
                            stderr=f"Pod {container_id} not found",
                            exit_code=1,
                        )
                    raise

        try:
            if timeout:
                return await asyncio.wait_for(_wait(), timeout=timeout)
            else:
                return await _wait()

        except asyncio.TimeoutError:
            logger.warning(f"Pod {container_id} timed out")
            return ContainerResult(
                status="timeout",
                stdout="",
                stderr=f"Pod execution timed out after {timeout}s",
                exit_code=124,
            )

    async def ping(self) -> bool:
        """
        æ£€æŸ¥ Kubernetes è¿æ¥çŠ¶æ€

        Returns:
            bool: è¿æ¥æ˜¯å¦æ­£å¸¸
        """
        try:
            await self._ensure_connected()
            await asyncio.to_thread(
                self._core_v1.list_namespace,
                limit=1,
            )
            return True
        except Exception as e:
            logger.error(f"Kubernetes ping failed: {e}")
            return False

    def _parse_memory_to_bytes(self, value: str) -> int:
        """
        è§£æå†…å­˜é™åˆ¶ä¸ºå­—èŠ‚æ•°

        Args:
            value: å¦‚ "512Mi", "1Gi"

        Returns:
            å­—èŠ‚æ•°
        """
        value = value.strip()
        if value.endswith("Gi") or value.endswith("GB") or value.endswith("G"):
            return int(float(value[:-2]) * 1024 * 1024 * 1024)
        elif value.endswith("Mi") or value.endswith("MB") or value.endswith("M"):
            return int(float(value[:-2]) * 1024 * 1024)
        elif value.endswith("Ki") or value.endswith("KB") or value.endswith("K"):
            return int(float(value[:-2]) * 1024)
        else:
            # é»˜è®¤ä¸º MB
            return int(float(value) * 1024 * 1024)

    def _parse_disk_to_bytes(self, value: str) -> int:
        """è§£æç£ç›˜é™åˆ¶ä¸ºå­—èŠ‚æ•°"""
        return self._parse_memory_to_bytes(value)
