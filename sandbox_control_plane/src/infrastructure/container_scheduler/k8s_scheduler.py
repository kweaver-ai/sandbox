"""
Kubernetes å®¹å™¨è°ƒåº¦å™¨

ä½¿ç”¨å®˜æ–¹ Python kubernetes å®¢æˆ·ç«¯å®ç° Pod çš„åˆ›å»ºå’Œç®¡ç†ã€‚

æ”¯æŒ S3 workspace æŒ‚è½½ï¼šå½“ workspace_path ä»¥ s3:// å¼€å¤´æ—¶ï¼Œ
Pod ä¼šé€šè¿‡ JuiceFS CSI Driver å°† S3 bucket æŒ‚è½½åˆ° /workspace ç›®å½•ã€‚

æ”¯æŒ Python ä¾èµ–å®‰è£…ï¼šæŒ‰ç…§ sandbox-design-v2.1.md ç« èŠ‚ 5 è®¾è®¡ã€‚
"""
import asyncio
import json
import os
from typing import Optional, List
from urllib.parse import urlparse

from kubernetes import client, config
from kubernetes.client import (
    V1Pod,
    V1PodSpec,
    V1ObjectMeta,
    V1Container,
    V1ContainerPort,
    V1EnvVar,
    V1ResourceRequirements,
    V1Volume,
    V1VolumeMount,
    V1PersistentVolumeClaimVolumeSource,
    V1PersistentVolumeClaim,
    V1PersistentVolumeClaimSpec,
    V1SecurityContext,
    V1Capabilities,
    V1PodSecurityContext,
    V1EmptyDirVolumeSource,
)
from kubernetes.client.rest import ApiException

from src.infrastructure.container_scheduler.base import (
    IContainerScheduler,
    ContainerConfig,
    ContainerInfo,
    ContainerResult,
)
from src.infrastructure.config.settings import get_settings
from src.infrastructure.logging import get_logger

logger = get_logger(__name__)


def s3_prefix_from_path(prefix: str) -> str:
    """
    ä» S3 è·¯å¾„å‰ç¼€ä¸­æå–ä¼šè¯ ID

    Args:
        prefix: S3 è·¯å¾„å‰ç¼€ï¼Œå¦‚ "sessions/test-001/workspace"

    Returns:
        ä¼šè¯ IDï¼Œå¦‚ "test-001"
    """
    parts = prefix.strip('/').split('/')
    if len(parts) >= 2 and parts[0] == "sessions":
        return parts[1]
    return prefix


class K8sScheduler(IContainerScheduler):
    """
    Kubernetes å®¹å™¨è°ƒåº¦å™¨

    é€šè¿‡ Kubernetes API ç®¡ç† Pod ç”Ÿå‘½å‘¨æœŸã€‚
    """

    def __init__(
        self,
        namespace: str = "sandbox-runtime",
        kube_config_path: Optional[str] = None,
        service_account_token: Optional[str] = None,
    ):
        """
        åˆå§‹åŒ– K8s è°ƒåº¦å™¨

        Args:
            namespace: Kubernetes å‘½åç©ºé—´
            kube_config_path: kubeconfig æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼Œç”¨äºæœ¬åœ°å¼€å‘ï¼‰
            service_account_token: ServiceAccount Tokenï¼ˆç”¨äº Pod å†…è¿è¡Œï¼‰
        """
        self._namespace = namespace

        # åŠ è½½ Kubernetes é…ç½®
        if service_account_token:
            # åœ¨ Pod å†…è¿è¡Œï¼Œä½¿ç”¨ ServiceAccount
            self._load_incluster_config()
        elif kube_config_path:
            # ä½¿ç”¨æŒ‡å®šçš„ kubeconfig æ–‡ä»¶
            config.load_kube_config(config_file=kube_config_path)
        else:
            # å°è¯•åŠ è½½é»˜è®¤ kubeconfig
            try:
                config.load_kube_config()
            except Exception:
                # å¦‚æœ kubeconfig ä¸å­˜åœ¨ï¼Œå°è¯•ä½¿ç”¨ in-cluster é…ç½®
                try:
                    self._load_incluster_config()
                except Exception:
                    # æœ€åå°è¯•ä½¿ç”¨é»˜è®¤é…ç½®ï¼ˆç”¨äºæœ¬åœ°å¼€å‘ï¼‰
                    from kubernetes.client import Configuration
                    Configuration.set_default(Configuration())

        # åˆ›å»º API å®¢æˆ·ç«¯
        self._core_v1 = client.CoreV1Api()
        self._initialized = False

    def _load_incluster_config(self):
        """åŠ è½½ in-cluster é…ç½®"""
        config.load_incluster_config()
        logger.info("Loaded in-cluster Kubernetes config")

    async def _ensure_connected(self) -> bool:
        """ç¡®ä¿ K8s è¿æ¥å·²å»ºç«‹"""
        if not self._initialized:
            try:
                # æµ‹è¯•è¿æ¥ - ä½¿ç”¨å½“å‰ namespace çš„ Pod åˆ—è¡¨ä»£æ›¿ namespace åˆ—è¡¨
                # è¿™æ ·åªéœ€è¦ namespace çº§åˆ«çš„æƒé™ï¼Œä¸éœ€è¦ cluster çº§åˆ«çš„æƒé™
                self._core_v1.list_namespaced_pod(self._namespace, limit=1)
                self._initialized = True
                logger.info(f"Connected to Kubernetes cluster, namespace: {self._namespace}")
            except Exception as e:
                logger.error(f"Failed to connect to Kubernetes: {e}")
                raise
        return self._initialized

    async def close(self) -> None:
        """å…³é—­è¿æ¥ï¼ˆKubernetes å®¢æˆ·ç«¯æ˜¯æ— çŠ¶æ€çš„ï¼Œæ— éœ€æ˜¾å¼å…³é—­ï¼‰"""
        self._initialized = False

    def _parse_s3_workspace(self, workspace_path: str) -> Optional[dict]:
        """
        è§£æ S3 workspace è·¯å¾„

        Args:
            workspace_path: S3 è·¯å¾„ï¼Œæ ¼å¼: s3://bucket/sessions/{session_id}/

        Returns:
            åŒ…å« bucket, prefix çš„å­—å…¸ï¼Œå¦‚æœä¸æ˜¯ S3 è·¯å¾„åˆ™è¿”å› None
        """
        if not workspace_path or not workspace_path.startswith("s3://"):
            return None

        parsed = urlparse(workspace_path)
        return {
            "bucket": parsed.netloc,
            "prefix": parsed.path.lstrip('/'),
        }

    def _build_pod_name(self, session_id: str) -> str:
        """ç”Ÿæˆ Pod åç§°"""
        # K8s Pod åç§°éœ€è¦ç¬¦åˆ DNS å­åŸŸåè§„åˆ™
        # åªèƒ½åŒ…å«å°å†™å­—æ¯ã€æ•°å­—å’Œ '-'ï¼Œä¸”å¼€å¤´å’Œç»“å°¾å¿…é¡»æ˜¯å­—æ¯æ•°å­—
        pod_name = f"sandbox-{session_id.lower()}"
        # æ›¿æ¢ä¸ç¬¦åˆè§„åˆ™çš„å­—ç¬¦
        pod_name = ''.join(c if c.isalnum() or c == '-' else '-' for c in pod_name)
        # ç¡®ä¿ä¸ä»¥ '-' å¼€å¤´æˆ–ç»“å°¾
        pod_name = pod_name.strip('-')
        # é™åˆ¶é•¿åº¦ï¼ˆK8s Pod åç§°æœ€å¤š 253 å­—ç¬¦ï¼‰
        return pod_name[:253]

    def _build_pvc_name(self, session_id: str) -> str:
        """
        ç”Ÿæˆ PVC åç§°

        åº”ç”¨ Kubernetes DNS å­åŸŸåè§„åˆ™ï¼Œç¡®ä¿ PVC åç§°ç¬¦åˆè§„èŒƒï¼š
        - åªèƒ½åŒ…å«å°å†™å­—æ¯ã€æ•°å­—å’Œ '-'
        - å¿…é¡»ä»¥å­—æ¯æ•°å­—å¼€å¤´å’Œç»“å°¾
        - æœ€å¤š 253 å­—ç¬¦

        Args:
            session_id: ä¼šè¯ ID

        Returns:
            DNS-compliant çš„ PVC åç§°
        """
        # è½¬æ¢ä¸ºå°å†™å¹¶æ›¿æ¢ä¸‹åˆ’çº¿ä¸ºè¿å­—ç¬¦
        sanitized = session_id.lower().replace('_', '-')
        # ç§»é™¤è¿ç»­çš„è¿å­—ç¬¦
        while '--' in sanitized:
            sanitized = sanitized.replace('--', '-')
        # ç§»é™¤å¼€å¤´å’Œç»“å°¾çš„è¿å­—ç¬¦
        sanitized = sanitized.strip('-')
        # é™åˆ¶é•¿åº¦ï¼ˆK8s PVC åç§°æœ€å¤š 253 å­—ç¬¦ï¼‰
        sanitized = sanitized[:253]
        return f"workspace-{sanitized}"

    def _build_executor_container(
        self,
        config: ContainerConfig,
        use_s3_mount: bool,
        has_dependencies: bool,
    ) -> V1Container:
        """
        æ„å»ºä¸» executor å®¹å™¨

        Args:
            config: å®¹å™¨é…ç½®
            use_s3_mount: æ˜¯å¦ä½¿ç”¨ S3 æŒ‚è½½ï¼ˆé€šè¿‡ JuiceFS CSI Driverï¼‰
            has_dependencies: æ˜¯å¦æœ‰ä¾èµ–åŒ…

        Returns:
            V1Container å¯¹è±¡
        """
        env_vars = [
            V1EnvVar(name=k, value=v)
            for k, v in config.env_vars.items()
        ]

        # æ·»åŠ  S3 ç›¸å…³ç¯å¢ƒå˜é‡
        s3_workspace = self._parse_s3_workspace(config.workspace_path)
        if s3_workspace:
            env_vars.extend([
                V1EnvVar(name="WORKSPACE_PATH", value="/workspace"),
                V1EnvVar(name="S3_BUCKET", value=s3_workspace["bucket"]),
                V1EnvVar(name="S3_PREFIX", value=s3_workspace["prefix"]),
            ])

        # æ·»åŠ  PYTHONPATH ç¯å¢ƒå˜é‡ä»¥æ”¯æŒä¾èµ–å¯¼å…¥
        if has_dependencies:
            # ä¾èµ–å®‰è£…åˆ°æœ¬åœ° /opt/sandbox-venv
            env_vars.append(V1EnvVar(
                name="PYTHONPATH",
                value="/opt/sandbox-venv:/app:/workspace"
            ))
            env_vars.append(V1EnvVar(
                name="SANDBOX_VENV_PATH",
                value="/opt/sandbox-venv"
            ))

        # èµ„æºé™åˆ¶
        resources = V1ResourceRequirements(
            limits={
                "cpu": config.cpu_limit,
                "memory": config.memory_limit,
                "ephemeral-storage": config.disk_limit,
            },
            requests={
                "cpu": config.cpu_limit,
                "memory": config.memory_limit,
            },
        )

        # å®¹å™¨ç«¯å£
        ports = [
            V1ContainerPort(
                container_port=8080,
                name="executor",
                protocol="TCP",
            )
        ]

        # å·æŒ‚è½½
        volume_mounts = [
            V1VolumeMount(
                name="workspace",
                mount_path="/workspace",
            )
        ]

        # å®‰å…¨ä¸Šä¸‹æ–‡
        security_context = V1SecurityContext(
            run_as_non_root=True,
            run_as_user=1000,
            run_as_group=1000,
            allow_privilege_escalation=False,
            capabilities=V1Capabilities(drop=["ALL"]),
            read_only_root_filesystem=False,
        )

        # å¦‚æœæœ‰ä¾èµ–å®‰è£…ï¼Œä½¿ç”¨å¯åŠ¨è„šæœ¬
        command = None
        if has_dependencies:
            # ä¾èµ–ç”± executor å®¹å™¨åœ¨å¯åŠ¨æ—¶å®‰è£…
            dependencies_json = config.labels.get("dependencies", "")
            dependencies = json.loads(dependencies_json) if dependencies_json else []

            pip_specs = []
            for dep in dependencies:
                if isinstance(dep, dict):
                    name = dep.get("name", "")
                    version = dep.get("version", "")
                    if version:
                        pip_specs.append(f"{name}{version}")
                    else:
                        pip_specs.append(name)
                elif isinstance(dep, str):
                    pip_specs.append(dep)

            deps_list = " ".join(f'"{spec}"' for spec in pip_specs)
            install_script = f"""
#!/bin/sh
set -e
echo "ğŸ“¦ Installing dependencies..."

# å°†ä¾èµ–å®‰è£…åˆ°å®¹å™¨æœ¬åœ°æ–‡ä»¶ç³»ç»Ÿ
VENV_DIR="/opt/sandbox-venv"
mkdir -p $VENV_DIR
mkdir -p /tmp/pip-cache

echo "Installing dependencies to: $VENV_DIR"

pip3 install \\
    --target $VENV_DIR \\
    --cache-dir /tmp/pip-cache \\
    --no-cache-dir \\
    --no-warn-script-location \\
    --disable-pip-version-check \\
    --index-url https://pypi.org/simple/ \\
    {deps_list}

echo "âœ… Dependencies installed"
rm -rf /tmp/pip-cache

# å¯åŠ¨ executor
exec python -m executor.interfaces.http.rest
"""
            command = ["sh", "-c", install_script]

        return V1Container(
            name="executor",
            image=config.image,
            image_pull_policy="IfNotPresent",  # ä¼˜å…ˆä½¿ç”¨æœ¬åœ°é•œåƒ
            command=command,
            env=env_vars,
            resources=resources,
            ports=ports,
            volume_mounts=volume_mounts,
            security_context=security_context,
        )

    async def create_pvc_for_workspace(
        self,
        session_id: str,
        workspace_path: str,
    ) -> Optional[str]:
        """
        ä¸º S3 workspace åˆ›å»º PVC (ä½¿ç”¨ CSI Driver)

        å½“ use_csi_driver é…ç½®å¯ç”¨æ—¶ï¼Œæ­¤æ–¹æ³•ä¼šåˆ›å»ºä¸€ä¸ªæŒ‡å‘ JuiceFS CSI Driver
        çš„ PVCï¼Œè¯¥ PVC ä¼šå°† S3 bucket æŒ‚è½½åˆ°å®¹å™¨ä¸­ã€‚

        Args:
            session_id: ä¼šè¯ ID
            workspace_path: S3 workspace è·¯å¾„ (s3://bucket/sessions/xxx/)

        Returns:
            PVC åç§°ï¼Œå¦‚æœä¸éœ€è¦ PVC åˆ™è¿”å› None
        """
        s3_workspace = self._parse_s3_workspace(workspace_path)
        if not s3_workspace:
            return None

        settings = get_settings()

        # æ£€æŸ¥æ˜¯å¦å¯ç”¨ CSI Driver
        if not settings.use_csi_driver:
            return None

        # ç”Ÿæˆ DNS-compliant çš„ PVC åç§°
        pvc_name = self._build_pvc_name(session_id)

        pvc = V1PersistentVolumeClaim(
            metadata=V1ObjectMeta(
                name=pvc_name,
                namespace=self._namespace,
                labels={
                    "app": "sandbox-executor",
                    "sandbox-session": session_id,
                    "s3-bucket": s3_workspace["bucket"],
                    "s3-prefix": s3_prefix_from_path(s3_workspace["prefix"]),
                },
                annotations={
                    "sandbox-session-id": session_id,
                    "workspace-path": workspace_path,
                },
            ),
            spec=V1PersistentVolumeClaimSpec(
                access_modes=["ReadWriteMany"],
                storage_class_name=settings.csi_storage_class,
                resources=V1ResourceRequirements(
                    requests={"storage": "1Pi"}  # JuiceFS ä½¿ç”¨è™šæ‹Ÿå¤§å°ï¼Œä¸å½±å“å®é™…å­˜å‚¨
                ),
            ),
        )

        try:
            await asyncio.to_thread(
                self._core_v1.create_namespaced_persistent_volume_claim,
                namespace=self._namespace,
                body=pvc,
            )
            logger.info(f"Created PVC {pvc_name} for session {session_id} using CSI driver")
            return pvc_name
        except ApiException as e:
            logger.error(f"Failed to create PVC for session {session_id}: {e}")
            raise

    async def delete_pvc_for_workspace(
        self,
        pvc_name: str,
        grace_period_seconds: int = 0
    ) -> None:
        """
        åˆ é™¤ S3 workspace PVC

        Args:
            pvc_name: PVC åç§°
            grace_period_seconds: å®½é™æœŸï¼ˆç§’ï¼‰
        """
        try:
            await asyncio.to_thread(
                self._core_v1.delete_namespaced_persistent_volume_claim,
                name=pvc_name,
                namespace=self._namespace,
                grace_period_seconds=grace_period_seconds,
            )
            logger.info(f"Deleted PVC {pvc_name}")
        except ApiException as e:
            if e.status != 404:
                logger.warning(f"Failed to delete PVC {pvc_name}: {e}")

    async def create_container(self, config: ContainerConfig) -> str:
        """
        åˆ›å»º Kubernetes Pod

        Pod é…ç½®ï¼š
        - ä¸»å®¹å™¨: executorï¼ˆè¿è¡Œç”¨æˆ·ä»£ç ï¼‰

        S3 Workspace æŒ‚è½½ï¼š
        å½“ workspace_path ä»¥ s3:// å¼€å¤´æ—¶ï¼Œä½¿ç”¨ JuiceFS CSI Driver åˆ›å»º PVCï¼Œ
        S3 bucket ä¼šè‡ªåŠ¨æŒ‚è½½åˆ°å®¹å™¨çš„ /workspace ç›®å½•ã€‚

        Python ä¾èµ–å®‰è£…ï¼š
        - å¦‚æœæœ‰ä¾èµ–ï¼Œexecutor å®¹å™¨ä¼šåœ¨å¯åŠ¨æ—¶å®‰è£…ä¾èµ–
        """
        await self._ensure_connected()

        pod_name = self._build_pod_name(config.name)
        s3_workspace = self._parse_s3_workspace(config.workspace_path)
        use_s3_mount = s3_workspace is not None

        # æ£€æŸ¥æ˜¯å¦æœ‰ä¾èµ–
        dependencies_json = config.labels.get("dependencies", "")
        has_dependencies = bool(dependencies_json)

        # åˆ›å»º PVCï¼ˆå¦‚æœéœ€è¦ S3 æŒ‚è½½ï¼‰
        pvc_name = None
        if use_s3_mount:
            pvc_name = await self.create_pvc_for_workspace(
                session_id=config.name,
                workspace_path=config.workspace_path,
            )

        # æ„å»ºå®¹å™¨åˆ—è¡¨
        containers = []

        # ä¸» executor å®¹å™¨
        executor_container = self._build_executor_container(
            config=config,
            use_s3_mount=use_s3_mount,
            has_dependencies=has_dependencies,
        )
        containers.append(executor_container)

        # æ„å»ºå·
        volumes = []
        if pvc_name:
            # S3 æŒ‚è½½ï¼šä½¿ç”¨ PVC
            volumes.append(
                V1Volume(
                    name="workspace",
                    persistent_volume_claim=V1PersistentVolumeClaimVolumeSource(
                        claim_name=pvc_name,
                    ),
                )
            )
        else:
            # æœ¬åœ° workspaceï¼šä½¿ç”¨ emptyDir
            volumes.append(
                V1Volume(
                    name="workspace",
                    empty_dir=V1EmptyDirVolumeSource(),
                )
            )

        # æ„å»ºæ ‡ç­¾
        labels = {
            "app": "sandbox-executor",  # åŒ¹é… sandbox-executor service selector
            "sandbox-session": config.name,
            "sandbox-type": "execution",
        }
        if pvc_name:
            labels["csi-driver"] = "juicefs"
        labels.update(config.labels)

        # æ„å»º Pod Spec
        pod = V1Pod(
            metadata=V1ObjectMeta(
                name=pod_name,
                labels=labels,
                annotations={
                    "sandbox-session-id": config.name,
                },
            ),
            spec=V1PodSpec(
                containers=containers,
                volumes=volumes,
                restart_policy="Never",
                host_network=False,
                termination_grace_period_seconds=30,
                # ä½¿ç”¨é»˜è®¤ DNS ç­–ç•¥ (ClusterFirst)ï¼Œå…è®¸ Pod ä½¿ç”¨ K8s é›†ç¾¤ DNS
                # è¿™å¯¹äº executor ä¸ control plane é€šä¿¡å¾ˆé‡è¦
            ),
        )

        try:
            # åˆ›å»º Pod
            created_pod = await asyncio.to_thread(
                self._core_v1.create_namespaced_pod,
                namespace=self._namespace,
                body=pod,
            )
            mount_method = "CSI" if pvc_name else "emptyDir"
            logger.info(
                f"Created pod {created_pod.metadata.name} for session {config.name} "
                f"in namespace {self._namespace} (mount method: {mount_method})"
            )
            return created_pod.metadata.name

        except ApiException as e:
            logger.error(f"Failed to create pod: {e}")
            # æ¸…ç†å·²åˆ›å»ºçš„ PVCï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            if pvc_name:
                await self.delete_pvc_for_workspace(pvc_name, grace_period_seconds=0)
            raise

    async def start_container(self, container_id: str) -> None:
        """
        å¯åŠ¨ Pod

        æ³¨æ„ï¼šKubernetes Pod åˆ›å»ºåä¼šè‡ªåŠ¨å¯åŠ¨ï¼Œæ­¤æ–¹æ³•ä¸ºå…¼å®¹æ¥å£ä¿ç•™
        """
        await self._ensure_connected()
        # K8s Pod åˆ›å»ºåè‡ªåŠ¨å¯åŠ¨ï¼Œæ— éœ€æ˜¾å¼è°ƒç”¨
        logger.debug(f"Pod {container_id} starts automatically after creation")

    async def stop_container(
        self,
        container_id: str,
        timeout: int = 30
    ) -> None:
        """
        åœæ­¢ï¼ˆåˆ é™¤ï¼‰Pod

        å¦‚æœä½¿ç”¨ CSI Driver ä¸”æœ‰å…³è”çš„ PVCï¼Œä¹Ÿä¼šåœ¨ Pod åˆ é™¤åæ¸…ç† PVCã€‚

        Args:
            container_id: Pod åç§°
            timeout: ä¼˜é›…ç»ˆæ­¢è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
        """
        await self._ensure_connected()

        # åœ¨åˆ é™¤ Pod ä¹‹å‰ï¼Œå…ˆè·å– PVC åç§°ï¼ˆå¦‚æœä½¿ç”¨ CSIï¼‰
        pvc_name = None
        try:
            pod = await asyncio.to_thread(
                self._core_v1.read_namespaced_pod,
                name=container_id,
                namespace=self._namespace,
            )
            # ä» Pod æ ‡ç­¾ä¸­è·å–ä¼šè¯ ID
            session_id = pod.metadata.labels.get("sandbox-session")
            if session_id and pod.metadata.labels.get("csi-driver") == "juicefs":
                pvc_name = self._build_pvc_name(session_id)
        except Exception:
            pass

        # åˆ é™¤ Pod
        try:
            await asyncio.to_thread(
                self._core_v1.delete_namespaced_pod,
                name=container_id,
                namespace=self._namespace,
                grace_period_seconds=timeout,
            )
            logger.info(f"Stopped pod {container_id}")
        except ApiException as e:
            if e.status == 404:
                logger.warning(f"Pod {container_id} not found")
            else:
                logger.error(f"Failed to stop pod {container_id}: {e}")
                raise

        # åˆ é™¤ PVCï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        if pvc_name:
            await self.delete_pvc_for_workspace(pvc_name)

    async def remove_container(
        self,
        container_id: str,
        force: bool = False
    ) -> None:
        """
        åˆ é™¤ Pod

        å¦‚æœä½¿ç”¨ CSI Driver ä¸”æœ‰å…³è”çš„ PVCï¼Œä¹Ÿä¼šåœ¨ Pod åˆ é™¤åæ¸…ç† PVCã€‚

        Args:
            container_id: Pod åç§°
            force: æ˜¯å¦å¼ºåˆ¶åˆ é™¤ï¼ˆgrace_period_seconds=0ï¼‰
        """
        await self._ensure_connected()

        # åœ¨åˆ é™¤ Pod ä¹‹å‰ï¼Œå…ˆè·å– PVC åç§°ï¼ˆå¦‚æœä½¿ç”¨ CSIï¼‰
        pvc_name = None
        try:
            pod = await asyncio.to_thread(
                self._core_v1.read_namespaced_pod,
                name=container_id,
                namespace=self._namespace,
            )
            # ä» Pod æ ‡ç­¾ä¸­è·å–ä¼šè¯ ID
            session_id = pod.metadata.labels.get("sandbox-session")
            if session_id and pod.metadata.labels.get("csi-driver") == "juicefs":
                pvc_name = self._build_pvc_name(session_id)
        except Exception:
            pass

        # åˆ é™¤ Pod
        try:
            await asyncio.to_thread(
                self._core_v1.delete_namespaced_pod,
                name=container_id,
                namespace=self._namespace,
                grace_period_seconds=0 if force else 30,
            )
            logger.info(f"Removed pod {container_id}")
        except ApiException as e:
            if e.status == 404:
                logger.warning(f"Pod {container_id} not found")
            else:
                logger.warning(f"Failed to remove pod {container_id}: {e}")

        # åˆ é™¤ PVCï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        if pvc_name:
            await self.delete_pvc_for_workspace(pvc_name, grace_period_seconds=0 if force else 30)

    async def get_container_status(self, container_id: str) -> ContainerInfo:
        """
        è·å– Pod çŠ¶æ€

        Args:
            container_id: Pod åç§°

        Returns:
            ContainerInfo å¯¹è±¡
        """
        await self._ensure_connected()
        try:
            pod = await asyncio.to_thread(
                self._core_v1.read_namespaced_pod,
                name=container_id,
                namespace=self._namespace,
            )

            # è½¬æ¢ K8s Pod çŠ¶æ€åˆ° ContainerInfo
            phase = pod.status.phase
            if phase == "Running":
                # æ£€æŸ¥å®¹å™¨çŠ¶æ€
                if pod.status.container_statuses:
                    for container_status in pod.status.container_statuses:
                        if container_status.name == "executor":
                            if container_status.state.terminated:
                                phase = "exited"
                            elif container_status.state.waiting:
                                phase = "waiting"
                            break

            # è·å– IP åœ°å€
            ip_address = pod.status.pod_ip

            # è·å–æ—¶é—´ä¿¡æ¯
            created_at = pod.metadata.creation_timestamp.isoformat() if pod.metadata.creation_timestamp else ""
            started_at = pod.status.start_time.isoformat() if pod.status.start_time else None

            # è·å–é€€å‡ºç ï¼ˆå¦‚æœå·²ç»ˆæ­¢ï¼‰
            exit_code = None
            if pod.status.container_statuses:
                for container_status in pod.status.container_statuses:
                    if container_status.name == "executor" and container_status.state.terminated:
                        exit_code = container_status.state.terminated.exit_code
                        break

            # è·å–é•œåƒåç§°
            image = ""
            if pod.spec.containers:
                for container in pod.spec.containers:
                    if container.name == "executor":
                        image = container.image
                        break

            return ContainerInfo(
                id=container_id,
                name=container_id,
                image=image,
                status=phase.lower(),
                ip_address=ip_address,
                created_at=created_at,
                started_at=started_at,
                exited_at=None,
                exit_code=exit_code,
            )

        except ApiException as e:
            if e.status == 404:
                logger.error(f"Pod {container_id} not found")
                raise ValueError(f"Pod {container_id} not found") from e
            else:
                logger.error(f"Failed to get pod status {container_id}: {e}")
                raise

    async def is_container_running(self, container_id: str) -> bool:
        """
        æ£€æŸ¥ Pod æ˜¯å¦æ­£åœ¨è¿è¡Œ

        Args:
            container_id: Pod åç§°

        Returns:
            bool: Pod æ˜¯å¦è¿è¡Œä¸­
        """
        try:
            container_info = await self.get_container_status(container_id)
            return container_info.status == "running"
        except Exception as e:
            logger.warning(f"Failed to check pod {container_id} status: {e}")
            return False

    async def get_container_logs(
        self,
        container_id: str,
        tail: int = 100,
        since: Optional[str] = None
    ) -> str:
        """
        è·å– Pod æ—¥å¿—

        Args:
            container_id: Pod åç§°
            tail: è¿”å›æœ€åå‡ è¡Œ
            since: æ—¶é—´æˆ³ï¼ˆå¯é€‰ï¼‰

        Returns:
            æ—¥å¿—å­—ç¬¦ä¸²
        """
        await self._ensure_connected()
        try:
            logs = await asyncio.to_thread(
                self._core_v1.read_namespaced_pod_log,
                name=container_id,
                namespace=self._namespace,
                container="executor",
                tail_lines=tail,
                since_seconds=None,  # since_time éœ€è¦è½¬æ¢
            )
            return logs
        except ApiException as e:
            logger.error(f"Failed to get logs for pod {container_id}: {e}")
            raise

    async def wait_container(
        self,
        container_id: str,
        timeout: Optional[int] = None
    ) -> ContainerResult:
        """
        ç­‰å¾… Pod æ‰§è¡Œå®Œæˆ

        Args:
            container_id: Pod åç§°
            timeout: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰

        Returns:
            ContainerResult å¯¹è±¡
        """
        await self._ensure_connected()

        async def _wait() -> ContainerResult:
            while True:
                try:
                    pod = await asyncio.to_thread(
                        self._core_v1.read_namespaced_pod,
                        name=container_id,
                        namespace=self._namespace,
                    )

                    # æ£€æŸ¥ Pod çŠ¶æ€
                    if pod.status.phase == "Succeeded":
                        # è·å–æ—¥å¿—
                        logs = await self.get_container_logs(container_id, tail=-1)
                        return ContainerResult(
                            status="completed",
                            stdout=logs,
                            stderr="",
                            exit_code=0,
                        )
                    elif pod.status.phase == "Failed":
                        # è·å–æ—¥å¿—
                        logs = await self.get_container_logs(container_id, tail=-1)
                        return ContainerResult(
                            status="failed",
                            stdout=logs,
                            stderr="Pod failed",
                            exit_code=1,
                        )

                    # æ£€æŸ¥å®¹å™¨çŠ¶æ€
                    if pod.status.container_statuses:
                        for container_status in pod.status.container_statuses:
                            if container_status.name == "executor":
                                if container_status.state.terminated:
                                    logs = await self.get_container_logs(container_id, tail=-1)
                                    terminated = container_status.state.terminated
                                    return ContainerResult(
                                        status="completed" if terminated.exit_code == 0 else "failed",
                                        stdout=logs,
                                        stderr="",
                                        exit_code=terminated.exit_code,
                                    )

                    # ç­‰å¾…åé‡è¯•
                    await asyncio.sleep(1)

                except ApiException as e:
                    if e.status == 404:
                        return ContainerResult(
                            status="failed",
                            stdout="",
                            stderr=f"Pod {container_id} not found",
                            exit_code=1,
                        )
                    raise

        try:
            if timeout:
                return await asyncio.wait_for(_wait(), timeout=timeout)
            else:
                return await _wait()

        except asyncio.TimeoutError:
            logger.warning(f"Pod {container_id} timed out")
            return ContainerResult(
                status="timeout",
                stdout="",
                stderr=f"Pod execution timed out after {timeout}s",
                exit_code=124,
            )

    async def ping(self) -> bool:
        """
        æ£€æŸ¥ Kubernetes è¿æ¥çŠ¶æ€

        Returns:
            bool: è¿æ¥æ˜¯å¦æ­£å¸¸
        """
        try:
            await self._ensure_connected()
            # æµ‹è¯•è¿æ¥
            await asyncio.to_thread(
                self._core_v1.list_namespace,
                limit=1,
            )
            return True
        except Exception as e:
            logger.error(f"Kubernetes ping failed: {e}")
            return False

    def _parse_memory_to_bytes(self, value: str) -> int:
        """
        è§£æå†…å­˜é™åˆ¶ä¸ºå­—èŠ‚æ•°

        Args:
            value: å¦‚ "512Mi", "1Gi"

        Returns:
            å­—èŠ‚æ•°
        """
        value = value.strip()
        if value.endswith("Gi") or value.endswith("GB") or value.endswith("G"):
            return int(float(value[:-2]) * 1024 * 1024 * 1024)
        elif value.endswith("Mi") or value.endswith("MB") or value.endswith("M"):
            return int(float(value[:-2]) * 1024 * 1024)
        elif value.endswith("Ki") or value.endswith("KB") or value.endswith("K"):
            return int(float(value[:-2]) * 1024)
        else:
            # é»˜è®¤ä¸º MB
            return int(float(value) * 1024 * 1024)

    def _parse_disk_to_bytes(self, value: str) -> int:
        """è§£æç£ç›˜é™åˆ¶ä¸ºå­—èŠ‚æ•°"""
        return self._parse_memory_to_bytes(value)
