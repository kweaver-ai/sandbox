# 3. å…³é”®æµç¨‹è®¾è®¡ + 4. æ•°æ®æ¨¡å‹è®¾è®¡


> **æ–‡æ¡£å¯¼èˆª**: [è¿”å›é¦–é¡µ](index.md)


## 3. å…³é”®æµç¨‹è®¾è®¡
### 3.1 ä¼šè¯åˆ›å»ºæµç¨‹
![alt text](image-2.png)
```mermaid
sequenceDiagram
    participant Agent as AI Agent
    participant API as API Gateway
    participant SessionMgr as ä¼šè¯ç®¡ç†å™¨
    participant Scheduler as è°ƒåº¦å™¨
    participant WarmPool as é¢„çƒ­æ± 
    participant Runtime as è¿è¡Œæ—¶
    participant Container as å®¹å™¨å®ä¾‹
    
    Agent->>API: POST /sessions (template_id, resources)
    API->>SessionMgr: create_session()
    SessionMgr->>Scheduler: schedule(request)
    
    Scheduler->>WarmPool: acquire(template_id)
    alt é¢„çƒ­å®ä¾‹å¯ç”¨
        WarmPool-->>Scheduler: è¿”å›é¢„çƒ­å®ä¾‹
        Scheduler-->>SessionMgr: è¿”å›å®¹å™¨èŠ‚ç‚¹
    else æ— é¢„çƒ­å®ä¾‹
        Scheduler->>Runtime: é€‰æ‹©æœ€ä¼˜èŠ‚ç‚¹
        Runtime-->>Scheduler: è¿”å›èŠ‚ç‚¹ä¿¡æ¯
    end
    
    SessionMgr->>Runtime: create_container(session)
    Runtime->>Container: docker run / kubectl create pod
    Container-->>Runtime: å®¹å™¨å¯åŠ¨æˆåŠŸ
    Runtime-->>SessionMgr: è¿”å›å®¹å™¨ ID

    SessionMgr->>MariaDB: INSERT INTO sessions ...
    MariaDB-->>SessionMgr: ç¡®è®¤ä¿å­˜
    SessionMgr-->>API: è¿”å› session_id
    API-->>Agent: è¿”å›ä¼šè¯ä¿¡æ¯
```

### 3.2 ä»£ç æ‰§è¡Œæµç¨‹
![alt text](image-1.png)
```mermaid
sequenceDiagram
    participant Agent as AI Agent
    participant API as API Gateway
    participant SessionMgr as ä¼šè¯ç®¡ç†å™¨
    participant Runtime as è¿è¡Œæ—¶
    participant Executor as æ‰§è¡Œå™¨
    participant DB as MariaDB
    participant Volume as å¯¹è±¡å­˜å‚¨<br/>(Volume æŒ‚è½½)

    Agent->>API: POST /api/v1/sessions/{session_id}/execute (code, language)
    API->>SessionMgr: get_session(id)
    SessionMgr->>DB: SELECT * FROM sessions WHERE id=?
    DB-->>SessionMgr: è¿”å›ä¼šè¯ä¿¡æ¯
    SessionMgr-->>API: è¿”å›ä¼šè¯ä¿¡æ¯

    API->>DB: INSERT INTO executions (ç”Ÿæˆ execution_id)
    DB-->>API: è¿”å› execution_id

    API->>Runtime: execute_code(session_id, execution_id, request)
    Runtime->>Executor: é€šè¿‡å®¹å™¨å†… HTTP API å‘é€æ‰§è¡Œè¯·æ±‚

    Note over Executor,Volume: workspace ç›®å½•å·²é€šè¿‡ Volume æŒ‚è½½å¯¹è±¡å­˜å‚¨

    par å¼‚æ­¥æ‰§è¡Œ
        Executor->>Executor: è¿è¡Œä»£ç  (bwrap + subprocess)
        Executor->>Executor: æ”¶é›† stdout/stderr
        Executor->>Volume: ç”Ÿæˆæ–‡ä»¶å†™å…¥ workspace<br/>(è‡ªåŠ¨æŒä¹…åŒ–åˆ°å¯¹è±¡å­˜å‚¨)
        Executor->>Executor: æ‰«æç”Ÿæˆçš„æ–‡ä»¶åˆ—è¡¨
    end

    Executor->>API: POST /internal/executions/{execution_id}/result
    API->>DB: UPDATE executions (ä¿å­˜ stdout/stderr/çŠ¶æ€/æ–‡ä»¶åˆ—è¡¨)
    DB-->>API: ç¡®è®¤ä¿å­˜
    API-->>Executor: 200 OK

    API-->>Agent: è¿”å› execution_id (å·²æäº¤)

    Agent->>API: GET /api/v1/executions/{execution_id}/result
    API->>DB: SELECT * FROM executions WHERE id=?
    DB-->>API: è¿”å›ç»“æœæ•°æ® (stdout/stderr/artifacts)
    API-->>Agent: è¿”å›æ‰§è¡Œç»“æœ

    Note over Agent,Volume: å¦‚éœ€ä¸‹è½½æ–‡ä»¶ï¼Œé€šè¿‡æ–‡ä»¶ API ä»å¯¹è±¡å­˜å‚¨è·å–
```
### 3.3 å¥åº·æ£€æŸ¥ä¸æ•…éšœæ¢å¤æµç¨‹
![alt text](image-4.png)
```mermaid
sequenceDiagram
    participant Probe as ç›‘æ§æ¢é’ˆ
    participant Runtime as å®¹å™¨èŠ‚ç‚¹
    participant Scheduler as è°ƒåº¦å™¨
    participant SessionMgr as ä¼šè¯ç®¡ç†å™¨
    
    loop æ¯ 10 ç§’
        Probe->>Runtime: GET /health
        
        alt å¥åº·å“åº”
            Runtime-->>Probe: 200 OK + metrics
            Probe->>Probe: æ›´æ–°èŠ‚ç‚¹çŠ¶æ€
        else è¶…æ—¶æˆ–å¤±è´¥
            Runtime--xProbe: Timeout / Error
            Probe->>Probe: failure_count++
            
            alt failure_count >= 3
                Probe->>Scheduler: mark_unhealthy(node)
                Scheduler->>SessionMgr: migrate_sessions(node)
                
                loop å¯¹è¯¥èŠ‚ç‚¹çš„æ¯ä¸ªä¼šè¯
                    SessionMgr->>Scheduler: schedule(session)
                    Scheduler->>Runtime: åœ¨æ–°èŠ‚ç‚¹åˆ›å»ºä¼šè¯
                end
                
                Probe->>Scheduler: remove_node(node)
            end
        end
    end
```

## 4. æ•°æ®æ¨¡å‹è®¾è®¡


### 4.1 æ ¸å¿ƒå®ä½“æ¨¡å‹
```python
from enum import Enum
from pydantic import BaseModel
from datetime import datetime
from typing import Optional, Dict, List

class SessionStatus(str, Enum):
    CREATING = "creating"
    RUNNING = "running"
    COMPLETED = "completed"
    FAILED = "failed"
    TIMEOUT = "timeout"
    TERMINATED = "terminated"

class ResourceLimit(BaseModel):
    cpu: str = "1"  # CPU æ ¸å¿ƒæ•°
    memory: str = "512Mi"  # å†…å­˜é™åˆ¶
    disk: str = "1Gi"  # ç£ç›˜é™åˆ¶
    max_processes: int = 128  # æœ€å¤§è¿›ç¨‹æ•°

class Template(BaseModel):
    id: str
    name: str
    image: str  # Docker é•œåƒ
    base_image: str  # åŸºç¡€é•œåƒï¼ˆç”¨äºä¸¤é˜¶æ®µåŠ è½½ï¼‰
    pre_installed_packages: List[str]
    default_resources: ResourceLimit
    security_context: Dict[str, any]
    created_at: datetime

class Session(BaseModel):
    id: str
    template_id: str
    status: SessionStatus
    runtime_type: str  # "docker" or "kubernetes"
    runtime_node: str  # èŠ‚ç‚¹ ID
    container_id: Optional[str]
    pod_name: Optional[str]
    resources: ResourceLimit
    env_vars: Dict[str, str]
    created_at: datetime
    updated_at: datetime
    timeout: int  # è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰

class Execution(BaseModel):
    id: str
    session_id: str
    code: str
    language: str
    status: str  # "pending", "running", "completed", "failed"
    stdout: str
    stderr: str
    exit_code: int
    execution_time: float  # æ‰§è¡Œè€—æ—¶ï¼ˆç§’ï¼‰
    artifacts: List[Artifact]  # ç”Ÿæˆçš„æ–‡ä»¶å…ƒæ•°æ®åˆ—è¡¨
    # æ–°å¢å­—æ®µï¼šhandler è¿”å›å€¼å’Œæ€§èƒ½æŒ‡æ ‡
    return_value: Optional[dict] = None  # handler å‡½æ•°è¿”å›å€¼ï¼ˆJSON å¯åºåˆ—åŒ–ï¼‰
    metrics: Optional[dict] = None  # æ€§èƒ½æŒ‡æ ‡ï¼ˆduration_ms, cpu_time_ms, peak_memory_mb ç­‰ï¼‰
    created_at: datetime
    completed_at: Optional[datetime]

class Artifact(BaseModel):
    """æ–‡ä»¶å…ƒæ•°æ®æ¨¡å‹"""
    path: str  # ç›¸å¯¹äº workspace çš„æ–‡ä»¶è·¯å¾„ï¼Œå¦‚ "results/output.csv"
    size: int  # æ–‡ä»¶å¤§å°ï¼ˆå­—èŠ‚ï¼‰
    mime_type: str  # MIME ç±»å‹ï¼Œå¦‚ "text/csv"
    type: Literal["artifact", "log", "output"]  # æ–‡ä»¶ç±»å‹
    created_at: datetime  # åˆ›å»ºæ—¶é—´
    checksum: Optional[str] = None  # SHA256 æ ¡éªŒå’Œï¼ˆå¯é€‰ï¼‰
    download_url: Optional[str] = None  # ä¸‹è½½ URLï¼ˆé¢„ç­¾å S3 URLï¼‰

class RuntimeNode(BaseModel):
    id: str
    type: str  # "docker" or "kubernetes"
    url: str  # èŠ‚ç‚¹ API åœ°å€
    status: str  # "healthy", "unhealthy", "draining"
    cpu_usage: float  # 0.0 - 1.0
    mem_usage: float  # 0.0 - 1.0
    session_count: int
    max_sessions: int
    cached_templates: List[str]
    last_heartbeat: datetime
    failure_count: int
```

### 4.2 åè®®å®šä¹‰

#### 4.2.1 æ§åˆ¶å¹³é¢ APIï¼ˆå¤–éƒ¨ APIï¼‰

**è¯´æ˜**: ç”± AI Agent æˆ–ä¸Šå±‚æœåŠ¡è°ƒç”¨çš„å…¬å¼€ API æ¥å£ã€‚

```
# ä¼šè¯ç®¡ç†
POST   /api/v1/sessions                           # åˆ›å»ºä¼šè¯
GET    /api/v1/sessions/{id}                      # è·å–ä¼šè¯è¯¦æƒ…
GET    /api/v1/sessions                           # åˆ—å‡ºä¼šè¯
DELETE /api/v1/sessions/{id}                      # ç»ˆæ­¢ä¼šè¯

# ä»£ç æ‰§è¡Œ
POST   /api/v1/sessions/{session_id}/execute      # æäº¤æ‰§è¡Œä»»åŠ¡ï¼Œè¿”å› execution_id
GET    /api/v1/sessions/{session_id}/executions   # åˆ—å‡ºè¯¥ä¼šè¯çš„æ‰€æœ‰æ‰§è¡Œè®°å½•

# æ‰§è¡Œç»“æœæŸ¥è¯¢ï¼ˆåŸºäº execution_idï¼‰
GET    /api/v1/executions/{execution_id}          # è·å–æ‰§è¡Œè¯¦æƒ…ï¼ˆåŒ…å«ç»“æœï¼‰
GET    /api/v1/executions/{execution_id}/status   # è·å–æ‰§è¡ŒçŠ¶æ€ï¼ˆpending/running/completed/failedï¼‰
GET    /api/v1/executions/{execution_id}/result   # è·å–æ‰§è¡Œç»“æœï¼ˆstdout/stderr/exit_codeï¼‰

# æ–‡ä»¶æ“ä½œ
POST   /api/v1/sessions/{id}/files/upload         # ä¸Šä¼ æ–‡ä»¶åˆ°ä¼šè¯å·¥ä½œç›®å½•
GET    /api/v1/sessions/{id}/files/{name}         # ä¸‹è½½ä¼šè¯å·¥ä½œç›®å½•ä¸­çš„æ–‡ä»¶

# æ¨¡æ¿ç®¡ç†
POST   /api/v1/templates                          # åˆ›å»ºæ¨¡æ¿
GET    /api/v1/templates                          # åˆ—å‡ºæ¨¡æ¿
GET    /api/v1/templates/{id}                     # è·å–æ¨¡æ¿è¯¦æƒ…
PUT    /api/v1/templates/{id}                     # æ›´æ–°æ¨¡æ¿
DELETE /api/v1/templates/{id}                     # åˆ é™¤æ¨¡æ¿

# è¿è¡Œæ—¶ç®¡ç†
GET    /api/v1/runtimes                           # åˆ—å‡ºå®¹å™¨èŠ‚ç‚¹
GET    /api/v1/runtimes/{id}/health               # è·å–èŠ‚ç‚¹å¥åº·çŠ¶æ€
GET    /api/v1/runtimes/{id}/metrics              # è·å–èŠ‚ç‚¹æŒ‡æ ‡
```

**è¯·æ±‚/å“åº”ç¤ºä¾‹**ï¼š

```python
# æäº¤æ‰§è¡Œä»»åŠ¡
POST /api/v1/sessions/{session_id}/execute
Request:
{
    "code": "def handler(event):\n    return {'message': 'Hello', 'input': event.get('name', 'World')}",
    "language": "python",
    "timeout": 30,
    "event": {"name": "Alice"}
}

Response:
{
    "execution_id": "exec_1234567890",
    "status": "submitted",
    "submitted_at": "2025-01-04T10:30:00Z"
}

# æŸ¥è¯¢æ‰§è¡ŒçŠ¶æ€
GET /api/v1/executions/{execution_id}/status
Response:
{
    "execution_id": "exec_1234567890",
    "session_id": "sess_abc123",
    "status": "completed",
    "created_at": "2025-01-04T10:30:00Z",
    "completed_at": "2025-01-04T10:30:02Z"
}

# è·å–æ‰§è¡Œç»“æœ
GET /api/v1/executions/{execution_id}/result
Response:
{
    "execution_id": "exec_1234567890",
    "status": "success",
    "stdout": "Processing complete.\\n",
    "stderr": "",
    "exit_code": 0,
    "execution_time": 0.07523,
    "return_value": {
        "message": "Hello",
        "input": "Alice"
    },
    "metrics": {
        "duration_ms": 75.23,
        "cpu_time_ms": 68.12,
        "peak_memory_mb": 42.5
    },
    "artifacts": ["output.txt"]
}
```

#### 4.2.2 å†…éƒ¨å›è°ƒ APIï¼ˆç”± Executor è°ƒç”¨ï¼‰

**è¯´æ˜**: æ‰§è¡Œå™¨ï¼ˆè¿è¡Œåœ¨å®¹å™¨å†…çš„ sandbox-executorï¼‰è°ƒç”¨çš„å†…éƒ¨æ¥å£ï¼Œç”¨äºä¸ŠæŠ¥æ‰§è¡Œç»“æœã€‚

```
# æ‰§è¡Œç»“æœä¸ŠæŠ¥
POST   /internal/executions/{execution_id}/result    # ä¸ŠæŠ¥æ‰§è¡Œç»“æœï¼ˆå®Œæˆ/å¤±è´¥/è¶…æ—¶ï¼‰
POST   /internal/executions/{execution_id}/status    # ä¸ŠæŠ¥æ‰§è¡ŒçŠ¶æ€å˜æ›´ï¼ˆrunning/timeoutï¼‰

# è¯·æ±‚ä½“ç¤ºä¾‹ï¼š
POST /internal/executions/{execution_id}/result
{
    "status": "success",              # success | failed | timeout | error
    "stdout": "æ‰§è¡Œè¾“å‡ºå†…å®¹",
    "stderr": "é”™è¯¯è¾“å‡ºå†…å®¹",
    "exit_code": 0,
    "execution_time": 0.07523,
    "return_value": {                 # handler å‡½æ•°è¿”å›å€¼ï¼ˆJSON å¯åºåˆ—åŒ–ï¼‰
        "message": "Hello",
        "input": "Alice"
    },
    "metrics": {                      # æ€§èƒ½æŒ‡æ ‡
        "duration_ms": 75.23,
        "cpu_time_ms": 68.12,
        "peak_memory_mb": 42.5
    },
    "artifacts": ["generated_file.txt"]
}
```

**å®‰å…¨è¯´æ˜**: å†…éƒ¨ API åº”è¯¥ï¼š
- ä»…åœ¨å†…ç½‘/å®¹å™¨ç½‘ç»œä¸­å¯è®¿é—®
- ä½¿ç”¨è®¤è¯æœºåˆ¶ï¼ˆå¦‚ JWT token æˆ– API Keyï¼‰
- é™åˆ¶ä»…å®¹å™¨èŠ‚ç‚¹å¯è®¿é—®

**è¯´æ˜**: Container Scheduler ä½œä¸º Control Plane å†…éƒ¨æ¨¡å—ï¼Œé€šè¿‡ SDK ç›´æ¥è°ƒç”¨ Docker/K8s APIï¼Œæ— éœ€ç‹¬ç«‹çš„ HTTP APIã€‚

### 4.3 æ‰§è¡Œè¯­ä¹‰ä¸å¹‚ç­‰æ€§æ¨¡å‹

#### 4.3.1 execution_id ç”Ÿå‘½å‘¨æœŸ

æ¯ä¸ªä»£ç æ‰§è¡Œè¯·æ±‚éƒ½ä¼šè¢«åˆ†é…ä¸€ä¸ªå”¯ä¸€çš„ `execution_id`ï¼Œç”¨äºè¿½è¸ªæ•´ä¸ªæ‰§è¡Œè¿‡ç¨‹ã€‚

**execution_id ç”Ÿæˆè§„åˆ™**:
```python
execution_id = f"exec_{timestamp}_{uuid4()[:8]}"
# ç¤ºä¾‹: exec_20240115_abc12345
```

**ç”Ÿå‘½å‘¨æœŸçŠ¶æ€æœº**:
```mermaid
stateDiagram-v2
    [*] --> Pending: åˆ›å»º execution_id
    Pending --> Running: Executor å¼€å§‹æ‰§è¡Œ
    Running --> Completed: æ‰§è¡ŒæˆåŠŸ
    Running --> Failed: æ‰§è¡Œå¤±è´¥ï¼ˆè¯­æ³•é”™è¯¯/è¿è¡Œæ—¶é”™è¯¯ï¼‰
    Running --> Timeout: è¶…æ—¶
    Running --> Crashed: Executor å´©æºƒ
    Crashed --> Running: è‡ªåŠ¨é‡è¯•ï¼ˆæœ€å¤š 3 æ¬¡ï¼‰
    Crashed --> Failed: é‡è¯•æ¬¡æ•°è€—å°½
    Completed --> [*]
    Failed --> [*]
    Timeout --> [*]
```

**çŠ¶æ€è¯´æ˜**:

| çŠ¶æ€ | è¯´æ˜ | å¯å¦é‡è¯• |
|------|------|----------|
| `pending` | å·²åˆ›å»ºï¼Œç­‰å¾… Executor æ¥æ”¶ | æ˜¯ |
| `running` | Executor æ­£åœ¨æ‰§è¡Œ | å¦ |
| `completed` | æ‰§è¡ŒæˆåŠŸå®Œæˆ | å¦ |
| `failed` | æ‰§è¡Œå¤±è´¥ï¼ˆç”¨æˆ·ä»£ç é”™è¯¯ï¼‰ | å¦ |
| `timeout` | æ‰§è¡Œè¶…æ—¶ | å¯é€‰ï¼ˆç”±è°ƒç”¨æ–¹å†³å®šï¼‰ |
| `crashed` | Executor è¿›ç¨‹å´©æºƒ | æ˜¯ï¼ˆè‡ªåŠ¨é‡è¯•ï¼‰ |

#### 4.3.2 å¹‚ç­‰æ€§ä¿è¯

**At-Least-Once è¯­ä¹‰**:
- ç³»ç»Ÿä¿è¯æ¯ä¸ªæ‰§è¡Œè¯·æ±‚**è‡³å°‘è¢«æ‰§è¡Œä¸€æ¬¡**
- åœ¨ç½‘ç»œæ•…éšœã€Executor å´©æºƒç­‰åœºæ™¯ä¸‹å¯èƒ½ä¼šæ‰§è¡Œå¤šæ¬¡
- è°ƒç”¨æ–¹åº”è®¾è®¡å¹‚ç­‰å¤„ç†é€»è¾‘

**Exactly-Once è¯­ä¹‰ï¼ˆæœ‰é™ä¿è¯ï¼‰**:
- åœ¨æ­£å¸¸æƒ…å†µä¸‹ï¼ˆæ— å´©æºƒã€æ— ç½‘ç»œåˆ†åŒºï¼‰ï¼Œæ¯ä¸ª execution_id åªæ‰§è¡Œä¸€æ¬¡
- é€šè¿‡æ•°æ®åº“å”¯ä¸€çº¦æŸå’ŒçŠ¶æ€æœºä¿è¯ï¼š
  ```sql
  CREATE UNIQUE INDEX idx_execution_id ON executions(id);
  ```

**å¹‚ç­‰æ€§å»ºè®®**:
1. **è°ƒç”¨æ–¹å±‚é¢**:
   - å¯¹äºæœ‰å‰¯ä½œç”¨çš„æ“ä½œï¼ˆå¦‚å†™æ–‡ä»¶ï¼‰ï¼Œåº”å…ˆæ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
   - ä½¿ç”¨å¹‚ç­‰é”®ï¼ˆidempotency keyï¼‰å»é‡

2. **å¹³å°å±‚é¢**:
   - ç›¸åŒ execution_id çš„é‡å¤æäº¤è¿”å›å·²æœ‰ç»“æœ
   - æ–‡ä»¶å†™å…¥ä½¿ç”¨åŸå­æ“ä½œï¼ˆé‡å‘½åè€Œéè¦†ç›–ï¼‰

```python
# ç¤ºä¾‹ï¼šå¹‚ç­‰æ–‡ä»¶å†™å…¥
def write_output(filename: str, content: str):
    tmp_file = f"{filename}.tmp.{uuid4()}"
    with open(tmp_file, 'w') as f:
        f.write(content)
    os.rename(tmp_file, filename)  # åŸå­æ“ä½œ
```

#### 4.3.3 é‡è¯•æœºåˆ¶

**è‡ªåŠ¨é‡è¯•æ¡ä»¶**:
- Executor è¿›ç¨‹å´©æºƒï¼ˆexit_code = -1 æˆ–ä¿¡å·ç»ˆæ­¢ï¼‰
- ç½‘ç»œé€šä¿¡å¤±è´¥ï¼ˆè¶…è¿‡ 3 æ¬¡å¿ƒè·³è¶…æ—¶ï¼‰
- å®¹å™¨å¼‚å¸¸é€€å‡ºï¼ˆéç”¨æˆ·ä»£ç å¯¼è‡´çš„å¤±è´¥ï¼‰

**é‡è¯•ç­–ç•¥**:
```python
class RetryPolicy:
    max_attempts: int = 3  # æœ€å¤§é‡è¯•æ¬¡æ•°
    backoff_base: float = 1.0  # é€€é¿åŸºæ•°ï¼ˆç§’ï¼‰
    backoff_factor: float = 2.0  # é€€é¿å› å­
    max_backoff: float = 10.0  # æœ€å¤§é€€é¿æ—¶é—´

    def get_delay(attempt: int) -> float:
        """è®¡ç®—ç¬¬ N æ¬¡é‡è¯•çš„å»¶è¿Ÿæ—¶é—´"""
        delay = backoff_base * (backoff_factor ** (attempt - 1))
        return min(delay, max_backoff)

# é‡è¯•å»¶è¿Ÿåºåˆ—: 1s, 2s, 4s, 8s, 10s, 10s, ...
```

**ä¸é‡è¯•çš„åœºæ™¯**:
- ç”¨æˆ·ä»£ç é”™è¯¯ï¼ˆè¯­æ³•é”™è¯¯ã€ImportErrorã€NameError ç­‰ï¼‰
- è¶…æ—¶ï¼ˆtimeout çŠ¶æ€ï¼‰
- æ˜¾å¼å–æ¶ˆï¼ˆè°ƒç”¨æ–¹ä¸»åŠ¨ç»ˆæ­¢ï¼‰
- é‡è¯•æ¬¡æ•°å·²è¾¾ä¸Šé™

**é‡è¯•æ‰§è¡Œæµç¨‹**:
```python
async def retry_execution_if_needed(execution_id: str) -> bool:
    """åˆ¤æ–­å¹¶æ‰§è¡Œé‡è¯•"""
    execution = await db.get_execution(execution_id)

    if execution.status != ExecutionStatus.CRASHED:
        return False

    if execution.retry_count >= MAX_RETRY_ATTEMPTS:
        await mark_failed(execution_id, reason="Max retries exceeded")
        return False

    # è®¡ç®—é€€é¿å»¶è¿Ÿ
    delay = RetryPolicy.get_delay(execution.retry_count + 1)
    await asyncio.sleep(delay)

    # é‡æ–°è°ƒåº¦åˆ°ç›¸åŒ sessionï¼ˆå¤ç”¨ workspaceï¼‰
    await scheduler.resubmit(execution.session_id, execution_id)

    # æ›´æ–°é‡è¯•è®¡æ•°
    execution.retry_count += 1
    await db.commit()

    return True
```

#### 4.3.4 Executor å´©æºƒå¤„ç†

**å´©æºƒæ£€æµ‹æœºåˆ¶**:

1. **å¿ƒè·³æ£€æµ‹**:
   ```python
   # Executor æ¯ 5 ç§’å‘é€ä¸€æ¬¡å¿ƒè·³
   async def heartbeat_loop(execution_id: str):
       while True:
           await api.post(f"/internal/executions/{execution_id}/heartbeat")
           await asyncio.sleep(5)

   # Control Plane 15 ç§’æœªæ”¶åˆ°å¿ƒè·³åˆ™åˆ¤å®šä¸ºå´©æºƒ
   HEARTBEAT_TIMEOUT = 15
   ```

2. **å®¹å™¨çŠ¶æ€ç›‘æ§**:
   ```python
   # å¥åº·æ¢é’ˆæ£€æŸ¥å®¹å™¨çŠ¶æ€
   async def check_container_health(container_id: str):
       container = docker.containers.get(container_id)
       status = container.status

       if status in {"exited", "dead"}:
           return "crashed"
       elif status == "running":
           return "healthy"
       else:
           return "unknown"
   ```

**å´©æºƒæ¢å¤æµç¨‹**:
```mermaid
flowchart TD
    A[æ£€æµ‹åˆ°å´©æºƒ] --> B{å´©æºƒç±»å‹}
    B -->|å®¹å™¨é€€å‡º| C[æ ‡è®°ä¸º crashed]
    B -->|å¿ƒè·³è¶…æ—¶| D[æ£€æŸ¥å®¹å™¨çŠ¶æ€]

    D -->|å®¹å™¨æ­£å¸¸è¿è¡Œ| E[æ¢å¤å¿ƒè·³]
    D -->|å®¹å™¨å·²é€€å‡º| C

    C --> F{é‡è¯•æ¬¡æ•° < 3?}
    F -->|æ˜¯| G[å»¶è¿Ÿåé‡è¯•]
    F -->|å¦| H[æ ‡è®°ä¸º failed]

    G --> I[åˆ›å»ºæ–°å®¹å™¨/å¤ç”¨ session]
    I --> J[é‡æ–°æ‰§è¡Œç›¸åŒä»£ç ]
    J --> K{æ‰§è¡ŒæˆåŠŸ?}
    K -->|æ˜¯| L[æ ‡è®°ä¸º completed]
    K -->|å¦| C
```

**æ•°æ®ä¸€è‡´æ€§ä¿è¯**:

1. **æ‰§è¡Œç»“æœå¹‚ç­‰ä¸ŠæŠ¥**:
   ```python
   # Executor ä½¿ç”¨å¹‚ç­‰é”®ä¸ŠæŠ¥ç»“æœ
   async def report_result(execution_id: str, result: ExecutionResult):
       await api.post(
           f"/internal/executions/{execution_id}/result",
           json=result.dict(),
           headers={"Idempotency-Key": f"{execution_id}_result"}
       )
   ```

2. **Artifact æ–‡ä»¶åŸå­åŒ–**:
   - æ–‡ä»¶å…ˆå†™å…¥ä¸´æ—¶ç›®å½• `.tmp/{execution_id}/`
   - æ‰§è¡Œå®ŒæˆååŸå­ç§»åŠ¨åˆ° workspace
   - å´©æºƒæ—¶ä¸´æ—¶æ–‡ä»¶è‡ªåŠ¨æ¸…ç†

3. **æ•°æ®åº“äº‹åŠ¡éš”ç¦»**:
   ```sql
   -- ä½¿ç”¨ä¹è§‚é”é˜²æ­¢å¹¶å‘æ›´æ–°
   UPDATE executions
   SET status = 'completed',
       version = version + 1
   WHERE id = ? AND version = ?;
   ```

#### 4.3.5 æ‰§è¡Œç»“æœæŸ¥è¯¢

**æœ€ç»ˆä¸€è‡´æ€§**:
- æ‰§è¡Œå®Œæˆåç»“æœé€šå¸¸åœ¨ 100ms å†…å¯æŸ¥è¯¢
- åœ¨é«˜è´Ÿè½½ä¸‹å¯èƒ½æœ‰ 1-2 ç§’å»¶è¿Ÿ
- è°ƒç”¨æ–¹åº”ä½¿ç”¨è½®è¯¢æˆ– Webhook è·å–ç»“æœ

**æ¨èæŸ¥è¯¢æ¨¡å¼**:
```python
async def wait_for_result(execution_id: str, timeout: int = 60) -> ExecutionResult:
    """ç­‰å¾…æ‰§è¡Œç»“æœï¼ˆå¸¦è¶…æ—¶ï¼‰"""
    start = time.time()

    while True:
        result = await api.get(f"/api/v1/executions/{execution_id}")

        if result["status"] in {"completed", "failed", "timeout"}:
            return result

        if time.time() - start > timeout:
            raise TimeoutError(f"Execution {execution_id} query timeout")

        await asyncio.sleep(0.5)  # é€€é¿è½®è¯¢
```

#### 4.3.6 å¤±è´¥æ¢å¤è·¯å¾„

æœ¬èŠ‚æè¿°å„ç§æ•…éšœåœºæ™¯ä¸‹çš„æ¢å¤æœºåˆ¶ï¼Œç¡®ä¿ç³»ç»Ÿåœ¨å„ç§å¼‚å¸¸æƒ…å†µä¸‹çš„å¯ç”¨æ€§å’Œæ•°æ®ä¸€è‡´æ€§ã€‚

**æ•…éšœåˆ†ç±»**:

| æ•…éšœç±»å‹ | å½±å“èŒƒå›´ | æ¢å¤ç­–ç•¥ | æ•°æ®ä¸€è‡´æ€§ |
|----------|----------|----------|------------|
| Control Plane é‡å¯ | æ‰€æœ‰æ­£åœ¨è¿›è¡Œçš„è¯·æ±‚ | æ•°æ®åº“çŠ¶æ€æ¢å¤ + è¿è¡Œæ—¶é‡è¿ | å¼ºä¸€è‡´æ€§ |
| Executor å´©æºƒ | å•ä¸ªæ‰§è¡Œä»»åŠ¡ | è‡ªåŠ¨é‡è¯•ï¼ˆæœ€å¤š 3 æ¬¡ï¼‰ | At-Least-Once |
| Pod Eviction | æ•´ä¸ªæ²™ç®± Pod | é€æ˜é‡å»º + å¤ç”¨ workspace | At-Least-Once |
| ç½‘ç»œåˆ†åŒº | éƒ¨åˆ†èŠ‚ç‚¹ä¸å¯è¾¾ | è‡ªåŠ¨é‡è·¯ç”± + è¶…æ—¶é‡è¯• | æœ€ç»ˆä¸€è‡´æ€§ |
| èŠ‚ç‚¹æ•…éšœ | èŠ‚ç‚¹ä¸Šæ‰€æœ‰ Pod | è°ƒåº¦åˆ°å…¶ä»–èŠ‚ç‚¹ + é‡å»º | æœ€ç»ˆä¸€è‡´æ€§ |
| æ•°æ®åº“æ•…éšœ | æ‰€æœ‰å…ƒæ•°æ®æ“ä½œ | åªè¯»æ¨¡å¼ + é‡è¯• | å¼ºä¸€è‡´æ€§ |

**åœºæ™¯ 1: Control Plane é‡å¯**

```mermaid
flowchart TD
    A[Control Plane é‡å¯] --> B[ä»æ•°æ®åº“æ¢å¤çŠ¶æ€]
    B --> C{æ£€æŸ¥ running çŠ¶æ€çš„ executions}

    C --> D[æŸ¥è¯¢ last_heartbeat_at]
    D --> E{å¿ƒè·³è¶…æ—¶?}

    E -->|æ˜¯| F[æ ‡è®°ä¸º crashed]
    E -->|å¦| G[ä¿æŒ running çŠ¶æ€]

    F --> H[è§¦å‘é‡è¯•é€»è¾‘]
    G --> I[ç­‰å¾… Executor ä¸ŠæŠ¥ç»“æœ]

    H --> J[æ£€æŸ¥ session å®¹å™¨çŠ¶æ€]
    J --> K{å®¹å™¨å­˜åœ¨?}
    K -->|æ˜¯| L[å¤ç”¨ç°æœ‰å®¹å™¨]
    K -->|å¦| M[åˆ›å»ºæ–°å®¹å™¨]

    L --> N[é‡æ–°æ‰§è¡Œä»£ç ]
    M --> N
```

**æ¢å¤æµç¨‹**:

1. **å¯åŠ¨æ—¶çŠ¶æ€æ¢å¤**:
   ```python
   async def recover_on_startup():
       """Control Plane å¯åŠ¨æ—¶æ¢å¤çŠ¶æ€"""

       # 1. æŸ¥æ‰¾æ‰€æœ‰ running çŠ¶æ€çš„æ‰§è¡Œ
       running_executions = await db.query(
           SELECT * FROM executions
           WHERE status = 'running'
       )

       for execution in running_executions:
           # 2. æ£€æŸ¥å¿ƒè·³æ—¶é—´
           if execution.last_heartbeat_at < heartbeat_threshold():
               # å¿ƒè·³è¶…æ—¶ï¼Œæ ‡è®°ä¸ºå´©æºƒ
               await mark_crashed(execution.id)
               # è§¦å‘é‡è¯•
               await retry_execution_if_needed(execution.id)

       # 3. æ£€æŸ¥ session å®¹å™¨çŠ¶æ€
       sessions = await db.query(
           SELECT * FROM sessions
           WHERE status = 'running'
       )

       for session in sessions:
           is_alive = await check_container_status(session.container_id)
           if not is_alive:
               # å®¹å™¨å·²æ¶ˆå¤±ï¼Œæ ‡è®°ä¸ºå¾…é‡å»º
               await mark_session_unhealthy(session.id)
   ```

2. **è¿è¡Œæ—¶è¿æ¥æ¢å¤**:
   ```python
   async def reconnect_runtime_nodes():
       """é‡æ–°è¿æ¥æ‰€æœ‰å®¹å™¨èŠ‚ç‚¹"""
       nodes = await db.query(SELECT * FROM runtime_nodes)

       for node in nodes:
           try:
               # å‘é€å¥åº·æ£€æŸ¥
               await node.health_check()
               node.status = "healthy"
           except Exception:
               node.status = "unhealthy"

       await db.commit()
   ```

**åœºæ™¯ 2: Pod Eviction / èŠ‚ç‚¹ Drain**

å½“ Kubernetes èŠ‚ç‚¹éœ€è¦ç»´æŠ¤ï¼ˆå¦‚å‡çº§å†…æ ¸ï¼‰æ—¶ï¼ŒPod ä¼šè¢«ä¸»åŠ¨é©±é€ã€‚

```mermaid
flowchart TD
    A[Kubernetes å‘å‡º Eviction ä¿¡å·] --> B[Pod æ”¶åˆ° SIGTERM]
    B --> C[Executor å°è¯•ä¼˜é›…å…³é—­]

    C --> D{æ­£åœ¨æ‰§è¡Œçš„ä»»åŠ¡?}
    D -->|æ˜¯| E[æ ‡è®°å½“å‰æ‰§è¡Œä¸º crashed]
    D -->|å¦| F[ç›´æ¥é€€å‡º]

    E --> F
    F --> G[Pod è¢«åˆ é™¤]

    G --> H[Control Plane æ£€æµ‹åˆ° Pod æ¶ˆå¤±]
    H --> I[ä»æ•°æ®åº“æŸ¥è¯¢ session ä¿¡æ¯]

    I --> J[è°ƒåº¦åˆ°æ–°èŠ‚ç‚¹]
    J --> K[åˆ›å»ºæ–° Pod + æŒ‚è½½åŒä¸€ S3 workspace]

    K --> L[æ¢å¤ crashed çŠ¶æ€çš„ executions]
    L --> M[è‡ªåŠ¨é‡è¯•æ‰§è¡Œ]
```

**æ¢å¤æœºåˆ¶**:

1. **ä¼˜é›…å…³é—­å¤„ç†**:
   ```python
   # Executor æ”¶åˆ° SIGTERM æ—¶çš„å¤„ç†
   async def handle_shutdown():
       # 1. æ ‡è®°æ‰€æœ‰æ­£åœ¨æ‰§è¡Œçš„ä»»åŠ¡ä¸º crashed
       running_executions = get_running_executions()
       for exec_id in running_executions:
           await mark_crashed_via_callback(exec_id)

       # 2. æ¸…ç†ä¸´æ—¶æ–‡ä»¶
       cleanup_temp_files()

       # 3. æœ€å¤šç­‰å¾… 10 ç§’åå¼ºåˆ¶é€€å‡º
       await asyncio.sleep(10)
       sys.exit(143)  # SIGTERM exit code
   ```

2. **è·¨èŠ‚ç‚¹ä¼šè¯æ¢å¤**:
   ```python
   async def recover_session_on_eviction(session_id: str):
       """Pod é©±é€åæ¢å¤ä¼šè¯"""
       session = await db.get_session(session_id)

       # 1. è°ƒåº¦åˆ°æ–°çš„å¥åº·èŠ‚ç‚¹
       new_node = await scheduler.select_best_node(session.template_id)

       # 2. åœ¨æ–°èŠ‚ç‚¹ä¸Šåˆ›å»ºå®¹å™¨ï¼ŒæŒ‚è½½åŒä¸€ S3 workspace
       new_container_id = await new_node.create_container(
           session_id=session_id,
           workspace_path=session.workspace_path,  # å¤ç”¨ S3 è·¯å¾„
           template_id=session.template_id
       )

       # 3. æ›´æ–° session è®°å½•
       session.runtime_node = new_node.id
       session.container_id = new_container_id
       await db.commit()

       # 4. æ¢å¤æ‰€æœ‰ crashed çŠ¶æ€çš„æ‰§è¡Œ
       crashed_executions = await db.query(
           SELECT * FROM executions
           WHERE session_id = ? AND status = 'crashed'
       )

       for execution in crashed_executions:
           await retry_execution_if_needed(execution.id)
   ```

**åœºæ™¯ 3: ç½‘ç»œåˆ†åŒº**

ç½‘ç»œåˆ†åŒºå¯èƒ½å¯¼è‡´ Control Plane ä¸ å®¹å™¨èŠ‚ç‚¹ã€Executor ä¹‹é—´é€šä¿¡ä¸­æ–­ã€‚

```mermaid
flowchart TD
    A[ç½‘ç»œåˆ†åŒºå‘ç”Ÿ] --> B{å“ªäº›èŠ‚ç‚¹å—å½±å“?}

    B -->|å®¹å™¨èŠ‚ç‚¹ä¸å¯è¾¾| C[æ ‡è®°èŠ‚ç‚¹ä¸º unhealthy]
    B -->|Executor å¿ƒè·³ä¸¢å¤±| D[æ ‡è®°æ‰§è¡Œä¸º crashed]
    B -->|Control Plane ä¸å¯è¾¾| E[Executor æœ¬åœ°æŒä¹…åŒ–ç»“æœ]

    C --> F[åœæ­¢å‘è¯¥èŠ‚ç‚¹è°ƒåº¦æ–°ä»»åŠ¡]
    D --> G[è§¦å‘é‡è¯•é€»è¾‘]
    E --> H[ç½‘ç»œæ¢å¤åé‡è¯•ä¸ŠæŠ¥]

    F --> I[ç­‰å¾…ç½‘ç»œæ¢å¤]
    G --> I
    H --> I

    I --> J{ç½‘ç»œæ¢å¤?}
    J -->|æ˜¯| K[æ¢å¤æ­£å¸¸è°ƒåº¦]
    J -->|å¦| L[è¶…æ—¶åæ ‡è®°ä¸º failed]
```

**å¤„ç†ç­–ç•¥**:

1. **è¶…æ—¶ä¸é‡è¯•é…ç½®**:
   ```python
   class NetworkConfig:
       # HTTP å®¢æˆ·ç«¯é…ç½®
       connect_timeout: float = 5.0  # è¿æ¥è¶…æ—¶
       read_timeout: float = 30.0    # è¯»å–è¶…æ—¶
       max_retries: int = 3          # æœ€å¤§é‡è¯•æ¬¡æ•°

       # å¿ƒè·³é…ç½®
       heartbeat_interval: float = 5.0    # å¿ƒè·³é—´éš”
       heartbeat_timeout: float = 15.0    # å¿ƒè·³è¶…æ—¶

       # èŠ‚ç‚¹å¥åº·æ£€æŸ¥
       health_check_interval: float = 10.0
       node_unhealthy_threshold: int = 3  # è¿ç»­å¤±è´¥æ¬¡æ•°é˜ˆå€¼
   ```

2. **Executor æœ¬åœ°æŒä¹…åŒ–**:
   ```python
   # Executor åœ¨ Control Plane ä¸å¯è¾¾æ—¶æœ¬åœ°ä¿å­˜ç»“æœ
   async def report_result_with_fallback(execution_id: str, result: ExecutionResult):
       try:
           await api.post(f"/internal/executions/{execution_id}/result", json=result)
       except Exception as e:
           # ç½‘ç»œå¤±è´¥ï¼Œæœ¬åœ°æŒä¹…åŒ–
           local_path = f"/tmp/results/{execution_id}.json"
           with open(local_path, 'w') as f:
               json.dump(result.dict(), f)

           # åå°é‡è¯•ä»»åŠ¡
           asyncio.create_task(retry_report_when_available(execution_id, local_path))

   async def retry_report_when_available(execution_id: str, local_path: str):
       while True:
           try:
               with open(local_path, 'r') as f:
                   result = json.load(f)
               await api.post(f"/internal/executions/{execution_id}/result", json=result)
               os.remove(local_path)  # ä¸ŠæŠ¥æˆåŠŸï¼Œåˆ é™¤æœ¬åœ°æ–‡ä»¶
               break
           except Exception:
               await asyncio.sleep(5)  # 5 ç§’åé‡è¯•
   ```

**åœºæ™¯ 4: æ•°æ®åº“æ•…éšœ**

```mermaid
flowchart TD
    A[æ£€æµ‹åˆ°æ•°æ®åº“æ•…éšœ] --> B{æ•…éšœç±»å‹}

    B -->|è¿æ¥å¤±è´¥| C[åˆ‡æ¢åˆ°å¤‡ç”¨æ•°æ®åº“]
    B -->|ä¸»ä»åˆ‡æ¢| D[æ›´æ–°è¿æ¥æ± æŒ‡å‘æ–°ä¸»åº“]
    B -->|å®Œå…¨ä¸å¯ç”¨| E[è¿›å…¥åªè¯»é™çº§æ¨¡å¼]

    C --> F[é‡è¯•å¤±è´¥çš„æ“ä½œ]
    D --> F
    E --> G[æ‹’ç»å†™æ“ä½œ<br/>å…è®¸è¯»ç¼“å­˜]

    F --> H{æœåŠ¡æ¢å¤?}
    H -->|æ˜¯| I[æ¢å¤æ­£å¸¸æœåŠ¡]
    H -->|å¦| J[è¿”å› 503 Service Unavailable]

    G --> K[ç­‰å¾…æ•°æ®åº“æ¢å¤]
    K --> I
```

**é™çº§ç­–ç•¥**:

1. **åªè¯»æ¨¡å¼**:
   ```python
   class DatabaseManager:
       def __init__(self):
           self.read_only_mode = False
           self.cache = TTLCache(maxsize=1000, ttl=60)  # 1 åˆ†é’Ÿç¼“å­˜

       async def execute_write(self, query, params):
           if self.read_only_mode:
               raise ServiceUnavailable("Database in read-only mode")

           return await self.db.execute(query, params)

       async def execute_read(self, query, params):
           # ä¼˜å…ˆä»ç¼“å­˜è¯»å–
           cache_key = f"{query}:{params}"
           if cached := self.cache.get(cache_key):
               return cached

           result = await self.db.execute(query, params)
           self.cache[cache_key] = result
           return result
   ```

**åœºæ™¯ 5: S3 å¯¹è±¡å­˜å‚¨æ•…éšœ**

```mermaid
flowchart TD
    A[S3 ä¸ŠæŠ¥/ä¸‹è½½å¤±è´¥] --> B{æ“ä½œç±»å‹}

    B -->|Executor ä¸ŠæŠ¥ç»“æœ| C[æœ¬åœ°æŒä¹…åŒ– + é‡è¯•]
    B -->|ä¸‹è½½ artifact| D[è¿”å›é¢„ç­¾å URL<br/>å®¢æˆ·ç«¯ç›´æ¥ä¸‹è½½]
    B -->|åˆ›å»º workspace| E[ä½¿ç”¨æœ¬åœ°ä¸´æ—¶å­˜å‚¨]

    C --> F{é‡è¯•æˆåŠŸ?}
    F -->|æ˜¯| G[æ¸…ç†æœ¬åœ°å‰¯æœ¬]
    F -->|å¦| H[ä¿ç•™ 24 å°æ—¶ååˆ é™¤]

    D --> I[ç»•è¿‡ Control Plane]
    E --> J[é™çº§è­¦å‘Š]
```

**å®¹é”™æœºåˆ¶**:

1. **æœ¬åœ°ä¸´æ—¶å­˜å‚¨**:
   ```python
   # S3 ä¸å¯ç”¨æ—¶ä½¿ç”¨æœ¬åœ°å­˜å‚¨
   class ArtifactStorage:
       def __init__(self):
           self.s3_client = boto3.client('s3')
           self.fallback_path = "/tmp/artifacts"

       async def upload(self, file_path: str, s3_path: str):
           try:
               await self.s3_client.upload_file(file_path, bucket, s3_path)
           except Exception:
               # é™çº§åˆ°æœ¬åœ°å­˜å‚¨
               local_path = os.path.join(self.fallback_path, s3_path)
               os.makedirs(os.path.dirname(local_path), exist_ok=True)
               shutil.copy(file_path, local_path)
               logger.warning(f"S3 unavailable, using local storage: {local_path}")
   ```

2. **é¢„ç­¾å URL ç›´æ¥ä¸‹è½½**:
   ```python
   # ç»•è¿‡ Control Planeï¼Œå®¢æˆ·ç«¯ç›´æ¥ä» S3 ä¸‹è½½
   async def get_artifact_download_url(session_id: str, file_path: str) -> str:
       s3_path = f"sessions/{session_id}/{file_path}"
       url = s3_client.generate_presigned_url(
           'get_object',
           Params={'Bucket': S3_BUCKET, 'Key': s3_path},
           ExpiresIn=3600  # 1 å°æ—¶æœ‰æ•ˆæœŸ
       )
       return url
   ```

**æ¢å¤æ—¶é—´ç›®æ ‡ (RTO)**:

| æ•…éšœåœºæ™¯ | RTO | RPO | è¯´æ˜ |
|----------|-----|-----|------|
| Control Plane é‡å¯ | < 30s | 0 | å†…å­˜çŠ¶æ€å¯ä»æ•°æ®åº“æ¢å¤ |
| Executor å´©æºƒ | < 10s | 0 | è‡ªåŠ¨é‡è¯•ï¼Œæœ€å¤š 3 æ¬¡ |
| Pod Eviction | < 60s | 0 | è·¨èŠ‚ç‚¹æ¢å¤ï¼Œå¤ç”¨ S3 workspace |
| ç½‘ç»œåˆ†åŒº | < 30s | 0 | è¶…æ—¶é‡è¯• + è‡ªåŠ¨é‡è·¯ç”± |
| æ•°æ®åº“æ•…éšœ | < 60s | 0 | ä¸»ä»åˆ‡æ¢ |
| S3 æ•…éšœ | N/A | > 0 | é™çº§åˆ°æœ¬åœ°å­˜å‚¨ |

**æœ€ä½³å®è·µå»ºè®®**:

1. **å®šæœŸå¥åº·æ£€æŸ¥**:
   - æ¯ 10 ç§’æ£€æŸ¥ä¸€æ¬¡ å®¹å™¨èŠ‚ç‚¹å¥åº·çŠ¶æ€
   - æ¯ 5 ç§’æ£€æŸ¥ä¸€æ¬¡ Executor å¿ƒè·³
   - ä½¿ç”¨ Kubernetes liveness/readiness probe

2. **ä¼˜é›…å…³é—­**:
   - Control Plane æ”¶åˆ° SIGTERM æ—¶ï¼š
     - åœæ­¢æ¥å—æ–°è¯·æ±‚
     - ç­‰å¾…æ­£åœ¨å¤„ç†çš„è¯·æ±‚å®Œæˆï¼ˆæœ€å¤š 30 ç§’ï¼‰
     - æŒä¹…åŒ–å†…å­˜çŠ¶æ€åˆ°æ•°æ®åº“

3. **ç›‘æ§å‘Šè­¦**:
   - ç›‘æ§å´©æºƒé‡è¯•ç‡ï¼ˆåº” < 1%ï¼‰
   - ç›‘æ§å¿ƒè·³è¶…æ—¶æ¬¡æ•°ï¼ˆåº” < 0.1%ï¼‰
   - ç›‘æ§èŠ‚ç‚¹ä¸å¥åº·æ¯”ä¾‹ï¼ˆåº” < 10%ï¼‰
   - å‘Šè­¦é˜ˆå€¼ï¼šè¿ç»­ 3 æ¬¡é‡è¯•å¤±è´¥

### 4.4 S3 Workspace æŒ‚è½½æ¶æ„

**Implementation Status**: âœ… Fully Implemented

S3 workspace æŒ‚è½½ä½¿å®¹å™¨å†…çš„ç”¨æˆ·ä»£ç èƒ½å¤Ÿåƒè®¿é—®æœ¬åœ°æ–‡ä»¶ç³»ç»Ÿä¸€æ ·è®¿é—® S3 å¯¹è±¡å­˜å‚¨ï¼ˆMinIOï¼‰ã€‚

> **è¯¦ç»†æ–‡æ¡£**: å®Œæ•´çš„ S3 workspace æŒ‚è½½æ¶æ„ã€é…ç½®å’Œå®ç°ç»†èŠ‚è¯·å‚è€ƒ [10-minio-only-architecture.md](10-minio-only-architecture.md)ã€‚

#### å¿«é€Ÿæ¦‚è§ˆ

Kubernetes ç¯å¢ƒä½¿ç”¨ **s3fs + bind mount** æ–¹å¼å®ç° S3 workspace æŒ‚è½½ï¼š

- **æŒ‚è½½æ–¹å¼**: å®¹å™¨å†…å¯åŠ¨è„šæœ¬æŒ‚è½½ s3fsï¼Œä½¿ç”¨ bind mount è¦†ç›– /workspace
- **æŒ‚è½½æ—¶æœº**: å®¹å™¨å¯åŠ¨æ—¶é€šè¿‡å¯åŠ¨è„šæœ¬è‡ªåŠ¨å®Œæˆ
- **å­˜å‚¨åç«¯**: MinIOï¼ˆS3-compatible å¯¹è±¡å­˜å‚¨ï¼‰

**å…³é”®ç»„ä»¶**:
- Control Plane: Session Service + K8s Scheduler (s3fs mode)
- Executor Pod: å¯åŠ¨è„šæœ¬æŒ‚è½½ s3fs â†’ /mnt/s3-root â†’ bind mount â†’ /workspace
- Storage Layer: MinIO (sandbox-workspace bucket)

**é…ç½®è¦æ±‚**:
- S3 credentials (access key, secret key, endpoint URL)
- s3fs secret for executor pods
- S3-compatible storage (MinIO or AWS S3)

**æ–‡ä»¶æ“ä½œæµç¨‹**:
1. **ä¸Šä¼ **: Client â†’ File API â†’ S3Storage Service â†’ MinIO
2. **å®¹å™¨å†…è®¿é—®**: Executor â†’ POSIX I/O â†’ /workspace â†’ s3fs â†’ MinIO
3. **ä¸‹è½½**: Client â†’ File API â†’ presigned URL â†’ MinIO (direct)

**å®‰å…¨è€ƒè™‘**:
- SYS_ADMIN capability ä»…åœ¨ S3 workspace æ¨¡å¼ä¸‹å¯ç”¨
- ç”¨æˆ·é™æƒ (UID:GID 1000:1000)
- ç½‘ç»œéš”ç¦» (NetworkMode=none æˆ–ç‹¬ç«‹ç½‘ç»œ)

æœ‰å…³éƒ¨ç½²ã€éªŒè¯ã€æ•…éšœå¤„ç†å’Œæ€§èƒ½ä¼˜åŒ–çš„è¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚è€ƒ [10-minio-only-architecture.md](10-minio-only-architecture.md)ã€‚

## 5. Python ä¸‰æ–¹ä¾èµ–å®‰è£…æŠ€æœ¯æ–¹æ¡ˆ

### 5.1 æ¦‚è¿°

æœ¬ç« èŠ‚æè¿°æ²™ç®±å¹³å°çš„ **Python ä¸‰æ–¹ä¾èµ–è‡ªåŠ¨å®‰è£…åŠŸèƒ½**ã€‚è¯¥åŠŸèƒ½å…è®¸åœ¨åˆ›å»ºä¼šè¯æ—¶æŒ‡å®šéœ€è¦å®‰è£…çš„ Python åŒ…ï¼Œç³»ç»Ÿä¼šåœ¨å®¹å™¨å¯åŠ¨æ—¶è‡ªåŠ¨å®‰è£…è¿™äº›ä¾èµ–ï¼Œå¹¶æŒä¹…åŒ–åˆ° S3 workspaceã€‚

#### 5.1.1 æ ¸å¿ƒéœ€æ±‚

| éœ€æ±‚é¡¹ | è¯´æ˜ |
|-------|------|
| **å®‰è£…æ—¶æœº** | å®¹å™¨å¯åŠ¨æ—¶ï¼ˆåœ¨ entrypoint è„šæœ¬ä¸­è‡ªåŠ¨å®Œæˆï¼‰ |
| **ä½œç”¨åŸŸ** | ä¼šè¯çº§åˆ«ï¼ˆå®‰è£…åˆ°å®¹å™¨æœ¬åœ°æ–‡ä»¶ç³»ç»Ÿï¼‰ |
| **å®‰è£…ä½ç½®** | `/opt/sandbox-venv/`ï¼ˆæœ¬åœ°ç£ç›˜ï¼ŒéæŒä¹…åŒ–ï¼‰ |
| **ç½‘ç»œè®¿é—®** | å®¹å™¨ä½¿ç”¨ `sandbox_network`ï¼ˆbridgeï¼‰ï¼Œå¯è®¿é—® PyPI |
| **ç”¨æˆ·ä»£ç éš”ç¦»** | ç”¨æˆ·ä»£ç ä»ç„¶é€šè¿‡ Bubblewrap æ‰§è¡Œï¼ˆ`--unshare-net` æ— ç½‘ç»œï¼‰ |

#### 5.1.2 æ¶æ„å…¼å®¹æ€§

**ä¿æŒä¸å˜çš„ç°æœ‰é€»è¾‘**ï¼š
- âœ… `sandbox_network` (bridge)ï¼šå®¹å™¨é—´é€šä¿¡ï¼Œexecutor â†” control_plane
- âœ… `_build_s3_mount_entrypoint()`ï¼šS3 bucket æŒ‚è½½é€»è¾‘
- âœ… `gosu sandbox`ï¼šç”¨æˆ·åˆ‡æ¢é€»è¾‘
- âœ… Bubblewrapï¼šç”¨æˆ·ä»£ç æ‰§è¡Œéš”ç¦»ï¼ˆ`--unshare-net`ï¼‰

**æ–°å¢é€»è¾‘**ï¼š
- âœ… åœ¨ `gosu` åˆ‡æ¢å‰ï¼Œä»¥ root èº«ä»½å®‰è£…ä¾èµ–åˆ° `/opt/sandbox-venv/`ï¼ˆæœ¬åœ°ç£ç›˜ï¼‰
- âœ… å®‰è£…å®Œæˆå `chown -R sandbox:sandbox /opt/sandbox-venv/`
- âœ… ç„¶åæ‰§è¡Œ `gosu sandbox` å¯åŠ¨ executor
- âœ… è®¾ç½® `PYTHONPATH=/opt/sandbox-venv:/app:/workspace` ä½¿ä¾èµ–å¯å¯¼å…¥

### 5.2 æ ¸å¿ƒæµç¨‹

```mermaid
sequenceDiagram
    participant Client as ğŸ‘¤ Client
    participant API as ğŸŒ API Gateway
    participant SM as ğŸ“¦ Session Manager
    participant Scheduler as âš™ï¸ Scheduler
    participant Docker as ğŸ³ Docker Scheduler
    participant Entrypoint as ğŸ“œ Entrypoint Script
    participant Pip as ğŸ“¦ pip install
    participant Executor as âš¡ sandbox-executor
    participant S3 as ğŸ“¦ S3 Workspace

    Client->>API: POST /api/v1/sessions<br/>{dependencies: [{"name": "requests", "version": "==2.31.0"}]}
    API->>SM: create_session(command)

    SM->>SM: è§£æä¾èµ–åˆ—è¡¨<br/>dependencies = ["requests==2.31.0"]
    SM->>SM: ç‰ˆæœ¬å†²çªæ£€æµ‹ï¼ˆTemplate vs ç”¨æˆ·è¯·æ±‚ï¼‰

    SM->>Scheduler: schedule(config)
    Scheduler-->>SM: runtime_node

    SM->>Docker: create_container(config)<br/>config.labels["dependencies"] = ["requests==2.31.0"]

    Note over Docker: å®¹å™¨å¯åŠ¨ï¼ˆroot ç”¨æˆ·ï¼‰
    Docker->>Entrypoint: æ‰§è¡Œ entrypoint è„šæœ¬

    Entrypoint->>Entrypoint: 1. æŒ‚è½½ S3 bucketï¼ˆs3fsï¼‰
    Entrypoint->>Entrypoint: 2. åˆ›å»º /workspace ç¬¦å·é“¾æ¥
    Entrypoint->>Entrypoint: 3. æ£€æŸ¥ dependencies ç¯å¢ƒå˜é‡

    alt æœ‰ä¾èµ–éœ€è¦å®‰è£…
        Entrypoint->>Entrypoint: mkdir -p /opt/sandbox-venv/
        Entrypoint->>Pip: pip3 install --target /opt/sandbox-venv/ requests==2.31.0
        Pip->>Pip: ä» PyPI ä¸‹è½½å¹¶å®‰è£…
        Pip->>Entrypoint: å†™å…¥åˆ° /opt/sandbox-venv/ï¼ˆæœ¬åœ°ç£ç›˜ï¼‰
        Pip-->>Entrypoint: å®‰è£…æˆåŠŸ
        Entrypoint->>Entrypoint: chown -R sandbox:sandbox /opt/sandbox-venv/
    end

    Entrypoint->>Entrypoint: 4. gosu sandbox å¯åŠ¨ executor
    Entrypoint->>Executor: exec gosu sandbox python -m executor.interfaces.http.rest

    Executor->>API: ä¸ŠæŠ¥ readyï¼ˆä¾èµ–å·²å®‰è£…å®Œæˆï¼‰
    API-->>Client: Session created (status: running)

    Note over Client,S3: ç”¨æˆ·ä»£ç æ‰§è¡Œæ—¶ï¼Œå¯é€šè¿‡ import<br/>import requests  # å·²å®‰è£…åˆ° .venv/
```

### 5.3 API è®¾è®¡

#### 5.3.1 æ‰©å±•åˆ›å»ºä¼šè¯æ¥å£

**è¯·æ±‚æ¨¡å‹**ï¼š

```python
from typing import List, Optional
from pydantic import BaseModel, Field, field_validator

class DependencySpec(BaseModel):
    """ä¾èµ–åŒ…è§„èŒƒ"""
    name: str = Field(..., min_length=1, max_length=100, description="åŒ…åç§°")
    version: Optional[str] = Field(None, description="ç‰ˆæœ¬çº¦æŸ (å¦‚: ==2.31.0, >=1.0)")

    @field_validator("name")
    @classmethod
    def validate_package_name(cls, v: str) -> str:
        import re
        # ç¦æ­¢è·¯å¾„ç©¿è¶Š
        if ".." in v or v.startswith("/"):
            raise ValueError("Package name cannot contain path traversal characters")
        # ç¦æ­¢ URL
        if "://" in v:
            raise ValueError("Package name cannot contain URL")
        # PyPI åŒ…åè§„èŒƒ
        if not re.match(r"^[a-zA-Z0-9._-]+$", v):
            raise ValueError("Invalid package name format")
        return v

    def to_pip_spec(self) -> str:
        """è½¬æ¢ä¸º pip å®‰è£…è§„èŒƒ"""
        if self.version:
            return f"{self.name}{self.version}"
        return self.name

class CreateSessionRequest(BaseModel):
    """åˆ›å»ºä¼šè¯è¯·æ±‚ï¼ˆæ‰©å±•ç‰ˆï¼‰"""
    template_id: str
    timeout: int = 300
    cpu: str = "1"
    memory: str = "512Mi"
    disk: str = "1Gi"
    env_vars: Dict[str, str] = {}

    # æ–°å¢å­—æ®µ
    dependencies: List[DependencySpec] = Field(
        default_factory=list,
        max_length=50,
        description="ä¼šè¯çº§ä¾èµ–åŒ…åˆ—è¡¨"
    )
    install_timeout: int = Field(
        300,
        ge=30,
        le=1800,
        description="ä¾èµ–å®‰è£…è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰"
    )
    fail_on_dependency_error: bool = Field(
        True,
        description="ä¾èµ–å®‰è£…å¤±è´¥æ—¶æ˜¯å¦ç»ˆæ­¢ä¼šè¯åˆ›å»º"
    )
    allow_version_conflicts: bool = Field(
        False,
        description="æ˜¯å¦å…è®¸ç‰ˆæœ¬å†²çªï¼ˆTemplate é¢„è£…åŒ… vs ç”¨æˆ·è¯·æ±‚åŒ…ï¼‰"
    )
```

**è¯·æ±‚ç¤ºä¾‹**ï¼š

```bash
curl -X POST http://localhost:8000/api/v1/sessions \
  -H "Content-Type: application/json" \
  -d '{
    "template_id": "python3.11-baseline",
    "dependencies": [
      {"name": "requests", "version": "==2.31.0"},
      {"name": "pandas", "version": ">=2.0"},
      {"name": "numpy"}
    ],
    "install_timeout": 600,
    "fail_on_dependency_error": true
  }'
```

### 5.4 Docker Scheduler å®ç°

#### 5.4.1 ä¿®æ”¹ `_build_s3_mount_entrypoint()` æ–¹æ³•

**æ–‡ä»¶**: `sandbox_control_plane/src/infrastructure/container_scheduler/docker_scheduler.py`

**ç°æœ‰ç­¾å**ï¼š

```python
def _build_s3_mount_entrypoint(
    self,